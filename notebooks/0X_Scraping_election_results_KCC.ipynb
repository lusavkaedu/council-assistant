{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542b3ca1",
   "metadata": {},
   "source": [
    "### Scrape REGULAR elections results from a landing page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903a937",
   "metadata": {},
   "source": [
    "The settings are at the bottom of the main function - untoggle as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ce60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://democracy.kent.gov.uk:9071\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; ElectionScraper/1.0)\"\n",
    "}\n",
    "\n",
    "def scrape_election(eid, election_date, rpid=None):\n",
    "    print(f\"\\nüìã Scraping election {eid} on {election_date}...\\n\")\n",
    "\n",
    "    # Construct the master page URL\n",
    "    start_url = f\"{BASE_URL}/mgElectionElectionAreaResults.aspx?Page=all&EID={eid}\"\n",
    "    if rpid:\n",
    "        start_url += f\"&RPID={rpid}\"\n",
    "\n",
    "    # --- Step 1: Get all division result links\n",
    "    res = requests.get(start_url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    links = []\n",
    "    seen = set()\n",
    "\n",
    "    for a in soup.select(\"a\"):\n",
    "        href = a.get(\"href\", \"\")\n",
    "        text = a.get_text(strip=True)\n",
    "        if \"mgElectionAreaResults.aspx\" in href and \"ID=\" in href:\n",
    "            full_url = BASE_URL + \"/\" + href.lstrip(\"/\")\n",
    "            if full_url not in seen:\n",
    "                seen.add(full_url)\n",
    "                links.append((text, full_url))\n",
    "\n",
    "    print(f\"üîó Found {len(links)} division links...\")\n",
    "\n",
    "    # --- Step 2: Scrape each division\n",
    "    results = []\n",
    "    failed = []\n",
    "\n",
    "    for i, (name, url) in enumerate(links):\n",
    "        print(f\"[{i+1}/{len(links)}] Scraping: {name}\")\n",
    "        try:\n",
    "            division_data = parse_division_page(name, url)\n",
    "            division_data[\"election_date\"] = election_date\n",
    "            results.append(division_data)\n",
    "            time.sleep(0.4)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed on {name}: {e}\")\n",
    "            failed.append({\"division\": name, \"url\": url, \"error\": str(e)})\n",
    "\n",
    "    # --- Step 3: Save results\n",
    "    out_file = f\"../data/elections/kent_results_{election_date}.json\"\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    if failed:\n",
    "        with open(f\"failed_{election_date}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed, f, indent=2)\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved {len(results)} results to '{out_file}'\")\n",
    "    if failed:\n",
    "        print(f\"‚ö†Ô∏è {len(failed)} divisions failed ‚Äî see 'failed_{election_date}.json'\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Helper: Parse individual division page\n",
    "# ------------------------------------------\n",
    "\n",
    "def parse_division_page(name, url):\n",
    "    res = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    tables = soup.select(\"table.mgStatsTable\")\n",
    "\n",
    "    if len(tables) < 1:\n",
    "        return {\n",
    "            \"division\": name,\n",
    "            \"url\": url,\n",
    "            \"status\": \"no_tables_found\"\n",
    "        }\n",
    "\n",
    "    # Try to locate correct tables by caption\n",
    "    candidate_table = next((t for t in tables if \"Candidate\" in t.get_text() or \"results\" in t.get_text().lower()), None)\n",
    "    summary_table = next((t for t in tables if \"Voting Summary\" in t.get_text()), None)\n",
    "\n",
    "    if not candidate_table or not summary_table:\n",
    "        return {\n",
    "            \"division\": name,\n",
    "            \"url\": url,\n",
    "            \"status\": \"incomplete_data\"\n",
    "        }\n",
    "\n",
    "    # --- Candidate table\n",
    "    candidates = []\n",
    "    candidate_rows = candidate_table.find_all(\"tr\")[1:]\n",
    "    for row in candidate_rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) != 5:\n",
    "            continue\n",
    "        candidates.append({\n",
    "            \"name\": cols[0],\n",
    "            \"party\": cols[1],\n",
    "            \"votes\": int(cols[2].replace(\",\", \"\")),\n",
    "            \"percentage\": cols[3],\n",
    "            \"outcome\": cols[4]\n",
    "        })\n",
    "\n",
    "    # --- Summary table\n",
    "    summary = {}\n",
    "    summary_rows = summary_table.find_all(\"tr\")[1:]\n",
    "    for row in summary_rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) != 2 or not cols[0].strip():\n",
    "            continue\n",
    "        key = cols[0].lower().replace(\" \", \"_\")\n",
    "        val = cols[1].replace(\",\", \"\")\n",
    "        summary[key] = int(val) if val.isdigit() else val\n",
    "\n",
    "    return {\n",
    "        \"division\": name,\n",
    "        \"url\": url,\n",
    "        \"status\": \"ok\",\n",
    "        \"candidates\": candidates,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "# ------------------------------------------\n",
    "# Example usage\n",
    "# ------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #scrape_election(eid=51, election_date=\"2025-05-01\")\n",
    "    #scrape_election(eid=32, election_date=\"2021-05-06\")\n",
    "    #scrape_election(eid=20, election_date=\"2017-05-04\")\n",
    "    # scrape_election(eid=12, election_date=\"2013-05-02\")\n",
    "    scrape_election(eid=3,  election_date=\"2009-06-04\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781aaf1",
   "metadata": {},
   "source": [
    "### By-election results scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dfb6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "BASE_URL = \"https://democracy.kent.gov.uk\"\n",
    "FINAL_HOST = \"https://democracy.kent.gov.uk:9071\"\n",
    "START_URL = f\"{BASE_URL}/mgManageElectionResults.aspx?bcr=1\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (compatible; ByElectionScraper/1.0)\"\n",
    "}\n",
    "\n",
    "def try_parse_int(s):\n",
    "    try:\n",
    "        return int(s.replace(\",\", \"\"))\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def parse_name_and_date(text):\n",
    "    \"\"\"\n",
    "    Extracts clean division name and ISO election date from mixed link formats.\n",
    "    Supports:\n",
    "        - \"Election results for Division Name, 6 July 2023\"\n",
    "        - \"Division Name by-election, 21/11/2024\"\n",
    "    \"\"\"\n",
    "    # Try flexible match: split last comma-separated part as date\n",
    "    match = re.match(r\"^(.*?),\\s*(\\d{1,2}[/\\s]\\w+[/\\s]\\d{4})$\", text)\n",
    "    if match:\n",
    "        name = match.group(1).strip()\n",
    "        date_str = match.group(2).strip()\n",
    "        try:\n",
    "            election_date = parse_date(date_str, dayfirst=True).date().isoformat()\n",
    "        except:\n",
    "            election_date = None\n",
    "        return name, election_date\n",
    "\n",
    "    # Fallback: just return as-is\n",
    "    return text.strip(), None\n",
    "\n",
    "def parse_division_page(name, url, election_date):\n",
    "    res = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    tables = soup.select(\"table.mgStatsTable\")\n",
    "\n",
    "    if not tables:\n",
    "        return {\"division\": name, \"url\": url, \"election_date\": election_date, \"status\": \"no_tables_found\"}\n",
    "\n",
    "    candidate_table = None\n",
    "    for table in tables:\n",
    "        headers = [th.get_text(strip=True).lower() for th in table.find_all(\"th\")]\n",
    "        if any(\"candidate\" in h or \"votes\" in h for h in headers):\n",
    "            candidate_table = table\n",
    "            break\n",
    "\n",
    "    summary_table = next((t for t in tables if \"Voting Summary\" in t.get_text()), None)\n",
    "\n",
    "    if not candidate_table:\n",
    "        return {\"division\": name, \"url\": url, \"election_date\": election_date, \"status\": \"no_candidate_table\"}\n",
    "\n",
    "    candidates = []\n",
    "    rows = candidate_table.find_all(\"tr\")[1:]\n",
    "    for row in rows:\n",
    "        cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "        if len(cols) >= 4:\n",
    "            candidate = {\n",
    "                \"name\": cols[0],\n",
    "                \"party\": cols[1],\n",
    "                \"votes\": try_parse_int(cols[2]),\n",
    "                \"percentage\": cols[3],\n",
    "            }\n",
    "            if len(cols) > 4:\n",
    "                candidate[\"outcome\"] = cols[4]\n",
    "            candidates.append(candidate)\n",
    "\n",
    "    summary = {}\n",
    "    if summary_table:\n",
    "        rows = summary_table.find_all(\"tr\")[1:]\n",
    "        for row in rows:\n",
    "            cols = [td.get_text(strip=True) for td in row.find_all(\"td\")]\n",
    "            if len(cols) == 2:\n",
    "                key = cols[0].lower().replace(\" \", \"_\")\n",
    "                summary[key] = try_parse_int(cols[1])\n",
    "\n",
    "    return {\n",
    "        \"division\": name,\n",
    "        \"election_date\": election_date,\n",
    "        \"url\": url,\n",
    "        \"status\": \"ok\",\n",
    "        \"candidates\": candidates,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "def scrape_byelection_results():\n",
    "    print(f\"üìã Scraping from: {START_URL}\")\n",
    "    res = requests.get(START_URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    links = []\n",
    "    for a in soup.select(\"a[href*='mgElectionResults.aspx?ID=']\"):\n",
    "        href = a.get(\"href\")\n",
    "        if not href:\n",
    "            continue\n",
    "        full_url = FINAL_HOST + \"/\" + href.lstrip(\"/\").replace(\"mgElectionResults\", \"mgElectionAreaResults\")\n",
    "        text = a.get_text(strip=True)\n",
    "        name, election_date = parse_name_and_date(text)\n",
    "        links.append((name, election_date, full_url))\n",
    "\n",
    "    print(f\"üîó Found {len(links)} byelection result links\")\n",
    "\n",
    "    results = []\n",
    "    failed = []\n",
    "\n",
    "    for i, (name, election_date, url) in enumerate(links):\n",
    "        print(f\"[{i+1}/{len(links)}] Scraping: {name} ({election_date})\")\n",
    "        try:\n",
    "            result = parse_division_page(name, url, election_date)\n",
    "            results.append(result)\n",
    "            time.sleep(0.4)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed: {name} ‚Äî {e}\")\n",
    "            failed.append({\"name\": name, \"url\": url, \"error\": str(e)})\n",
    "\n",
    "    # üö´ Step: Remove junk division entries like \"County Council, 01/05/2025\"\n",
    "    initial_count = len(results)\n",
    "    results = [r for r in results if not r.get(\"division\", \"\").strip().lower().startswith(\"county council\")]\n",
    "    removed = initial_count - len(results)\n",
    "\n",
    "    print(f\"\\nüßπ Removed {removed} invalid 'County Council' rows from results.\")\n",
    "\n",
    "    # ‚úÖ Save cleaned results\n",
    "    with open(\"../data/elections/kent_byelection_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # üö® Log failures if any\n",
    "    if failed:\n",
    "        with open(\"kent_byelection_failures.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed, f, indent=2)\n",
    "\n",
    "    print(f\"\\n‚úÖ Final saved: {len(results)} byelection results. {len(failed)} failed.\")\n",
    "\n",
    "    # Save successful results\n",
    "    with open(\"../data/elections/kent_byelection_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Save failed logs\n",
    "    if failed:\n",
    "        with open(\"kent_byelection_failures.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(failed, f, indent=2)\n",
    "\n",
    "    print(f\"\\n‚úÖ Scraped {len(results)} byelection results. {len(failed)} failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_byelection_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load byelection results\n",
    "byelection_path = Path(\"../data/elections/kent_byelection_results.json\")\n",
    "with open(byelection_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# Flatten each result (one row per division)\n",
    "df = pd.json_normalize(raw_data)\n",
    "\n",
    "# Show basic shape and column names\n",
    "print(f\"üì¶ Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\\n\")\n",
    "print(\"üßæ Columns:\", list(df.columns), \"\\n\")\n",
    "\n",
    "# Show missing value summary\n",
    "print(\"üîç Missing values per column:\\n\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Optional: View sample of incomplete rows\n",
    "print(\"\\nüß© Sample rows with missing values:\")\n",
    "display(df[df.isna().any(axis=1)].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8e5af",
   "metadata": {},
   "source": [
    "### Consolidate all jsons into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011084aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def merge_nested_jsonl_files(\n",
    "    folder_path=\"../data/elections/scrape_results/\",\n",
    "    output_path=\"../data/elections/kent_merged_elections_all_nested.jsonl\"\n",
    "):\n",
    "    merged = []\n",
    "    files = sorted(glob(os.path.join(folder_path, \"*_elections_nested*.jsonl\")))\n",
    "\n",
    "    for file_path in files:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    record = json.loads(line)\n",
    "                    merged.append(record)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipping malformed line in {file_path}: {e}\")\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Write output\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for record in merged:\n",
    "            f_out.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Merged {len(files)} files into '{output_path}' ({len(merged)} total elections)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_nested_jsonl_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2879e5ec",
   "metadata": {},
   "source": [
    "### Open the consolidated file for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb29aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSONL file\n",
    "jsonl_path = \"../data/elections/kent_merged_elections_all_nested.jsonl\"\n",
    "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a11606",
   "metadata": {},
   "source": [
    "### Election level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50404869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} election records\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31880db6",
   "metadata": {},
   "source": [
    "#### Assign urls for elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BASE URLs per council\n",
    "BASE_URLS = {\n",
    "    \"kent_cc\": \"https://democracy.kent.gov.uk\",\n",
    "    \"rtw_bc\": \"https://democracy.tunbridgewells.gov.uk\",\n",
    "    \"ashford_bc\": \"https://ashford.moderngov.co.uk\",\n",
    "    \"dartford_bc\": \"https://dartford.moderngov.co.uk\",\n",
    "    \"thanet_bc\": \"https://democracy.thanet.gov.uk\",\n",
    "    \"maidstone_bc\": \"https://maidstone.gov.uk\",\n",
    "    \"swale_bc\": \"https://services.swale.gov.uk\",\n",
    "    \"tonbridge_bc\": \"https://democracy.tmbc.gov.uk\",\n",
    "\n",
    "    # Add more councils if needed\n",
    "}\n",
    "\n",
    "def construct_election_url(election_id):\n",
    "    try:\n",
    "        council_id, eid_raw = election_id.rsplit(\"_\", 1)\n",
    "        eid = str(int(eid_raw))  # strip leading zeroes\n",
    "        base = BASE_URLS.get(council_id)\n",
    "        if base:\n",
    "            return f\"{base}/mgElectionElectionAreaResults.aspx?EID={eid}\"\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Inject election_url into each record\n",
    "for rec in data:\n",
    "    rec[\"election_url\"] = construct_election_url(rec[\"election_id\"])\n",
    "\n",
    "# Convert to DataFrame to check\n",
    "df = pd.DataFrame(data)\n",
    "df[[\"election_id\", \"election_url\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['election_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['election_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Step 1: Filter unknown election levels\n",
    "unknowns = df[df[\"election_level\"] == \"unknown\"].copy()\n",
    "\n",
    "# Step 2: Count by council_id\n",
    "print(\"üîç Unknown election levels by council:\")\n",
    "print(unknowns[\"council_id\"].value_counts(), \"\\n\")\n",
    "\n",
    "# Step 3: Review distinct election descriptions\n",
    "print(\"üìù Sample election descriptions with unknown level:\")\n",
    "print(unknowns[\"election_description\"].value_counts().head(30))\n",
    "\n",
    "# Step 4: Add HTML link column\n",
    "unknowns[\"link\"] = unknowns[\"election_url\"].apply(lambda u: f'<a href=\"{u}\" target=\"_blank\">view</a>')\n",
    "\n",
    "# Step 5: Display as HTML table with clickable links\n",
    "print(\"\\nüîé Example unknown elections:\")\n",
    "display(HTML(unknowns[[\"election_id\", \"council_id\",\"election_date\", \"election_description\", \"link\"]].head(10).to_html(escape=False, index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ff390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_election_level(description):\n",
    "    desc = description.lower()\n",
    "\n",
    "    if any(word in desc for word in [\"neighbourhood plan\", \"referendum\", \"parish\", \"town\"]):\n",
    "        return \"parish\"\n",
    "    if \"member of parliament\" in desc or \"mp\" in desc:\n",
    "        return \"parliamentary\"\n",
    "    if \"county\" in desc or \"kcc\" in desc:\n",
    "        return \"county\"\n",
    "    if \"ward\" in desc:\n",
    "        return \"borough\"\n",
    "    if \"district\" in desc:\n",
    "        return \"district\"\n",
    "    if \"pcc\" in desc or \"police\" in desc:\n",
    "        return \"pcc\"\n",
    "    if \"av referendum\" in desc or \"eu referendum\" in desc:\n",
    "        return \"national\"\n",
    "    \n",
    "    return \"unknown\"\n",
    "\n",
    "# Strip whitespace and fill missing\n",
    "df[\"election_level\"] = df[\"election_level\"].fillna(\"unknown\").str.strip()\n",
    "\n",
    "# Diagnose initial state\n",
    "print(\"üîé BEFORE:\")\n",
    "print(df[\"election_level\"].value_counts())\n",
    "\n",
    "# Apply reclassification\n",
    "mask = df[\"election_level\"] == \"unknown\"\n",
    "df.loc[mask, \"election_level\"] = df.loc[mask, \"election_description\"].apply(classify_election_level)\n",
    "\n",
    "# Diagnose result\n",
    "print(\"\\n‚úÖ AFTER:\")\n",
    "print(df[\"election_level\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch rule: if council_id contains 'cc' and election_level is still unknown ‚Üí set to 'county'\n",
    "mask = (df[\"election_level\"] == \"unknown\") & (df[\"council_id\"].str.contains(\"cc\", case=False, na=False))\n",
    "df.loc[mask, \"election_level\"] = \"county\"\n",
    "\n",
    "# Confirm the fix\n",
    "print(\"‚úÖ Updated election_level using council_id 'cc' rule.\")\n",
    "print(df[\"election_level\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5183c3",
   "metadata": {},
   "source": [
    "### Explore the divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode divisions from nested structure\n",
    "divisions = []\n",
    "\n",
    "for election in data:\n",
    "    for div in election.get(\"divisions\", []):\n",
    "        div_record = {\n",
    "            \"election_id\": election.get(\"election_id\"),\n",
    "            \"council_id\": election.get(\"council_id\"),\n",
    "            \"election_date\": election.get(\"election_date\"),\n",
    "            \"election_type\": election.get(\"election_type\"),\n",
    "            \"election_description\": election.get(\"election_description\"),\n",
    "            \"source_url\": election.get(\"source_url\"),\n",
    "            \"division_name\": div.get(\"division\"),\n",
    "            \"division_id\": div.get(\"division_id\"),\n",
    "            \"status\": div.get(\"status\"),\n",
    "            \"url\": div.get(\"url\"),\n",
    "            \"summary\": div.get(\"summary\"),\n",
    "            \"candidates\": div.get(\"candidates\")\n",
    "        }\n",
    "        divisions.append(div_record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_divisions = pd.DataFrame(divisions)\n",
    "\n",
    "# View the first few rows\n",
    "df_divisions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Basic Overview ===\n",
    "print(\"üìä Shape of df_divisions:\", df_divisions.shape)\n",
    "print(\"\\nüß± Columns:\\n\", df_divisions.columns.tolist())\n",
    "print(\"\\nüßæ Sample Rows:\")\n",
    "display(df_divisions.head(10))\n",
    "\n",
    "# === Nulls and Completeness ===\n",
    "print(\"\\nüîç Missing Values Summary:\")\n",
    "missing_summary = df_divisions.isnull().sum().sort_values(ascending=False)\n",
    "display(missing_summary[missing_summary > 0])\n",
    "\n",
    "# === Election Types and Councils ===\n",
    "print(\"\\nüìä Election types per council:\")\n",
    "display(df_divisions.groupby([\"council_id\", \"election_type\"]).size().unstack(fill_value=0))\n",
    "\n",
    "# === Division Name Frequency ===\n",
    "print(\"\\nüìç Most Frequent Division Names:\")\n",
    "display(df_divisions[\"division_name\"].value_counts().head(20))\n",
    "\n",
    "# === Summary stats: seats, votes, etc. ===\n",
    "print(\"\\nüìà Basic Summary Stats:\")\n",
    "df_divisions[\"seats\"] = df_divisions[\"summary\"].apply(lambda s: s.get(\"seats\") if isinstance(s, dict) else None)\n",
    "df_divisions[\"total_votes\"] = df_divisions[\"summary\"].apply(lambda s: s.get(\"total_votes\") if isinstance(s, dict) else None)\n",
    "df_divisions[\"turnout\"] = df_divisions[\"summary\"].apply(lambda s: s.get(\"turnout\") if isinstance(s, dict) else None)\n",
    "\n",
    "display(df_divisions[[\"seats\", \"total_votes\"]].describe())\n",
    "\n",
    "# === Turnout Parsing (if percentage strings like \"45%\") ===\n",
    "df_divisions[\"turnout_pct\"] = (\n",
    "    df_divisions[\"turnout\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\"%\", \"\")\n",
    "    .str.extract(r\"(\\d+\\.?\\d*)\")[0]\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "print(\"\\nüìâ Turnout Stats (where available):\")\n",
    "display(df_divisions[\"turnout_pct\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code below:\n",
    "#* \tLooks for duplicate division names on the same date,\n",
    "#* \tFlags them,\n",
    "#* \tOutputs a diagnostic,\n",
    "#* \tRemoves them safely.\n",
    "\n",
    "# Step 1: Sort with kent_cc on top, so we keep it if it exists\n",
    "df_divisions_sorted = df_divisions.sort_values(\n",
    "    by=[\"election_date\", \"division_name\", \"council_id\"], \n",
    "    ascending=[True, True, False]  # False puts 'kent_cc' first if it exists\n",
    ")\n",
    "\n",
    "# Step 2: Drop duplicates keeping first (which will be kent_cc if present)\n",
    "df_deduped = df_divisions_sorted.drop_duplicates(\n",
    "    subset=[\"election_date\", \"division_name\"], keep=\"first\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Step 3: Diagnostics\n",
    "removed = len(df_divisions) - len(df_deduped)\n",
    "print(f\"‚úÖ Removed {removed} duplicate division records (kept 1 per date+division).\")\n",
    "\n",
    "# Optionally overwrite\n",
    "df_divisions = df_deduped\n",
    "df_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dec234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_divisions.drop(columns=[\"source_url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract total_votes into a flat list\n",
    "df_divisions[\"total_votes\"] = df_divisions[\"summary\"].apply(lambda x: x.get(\"total_votes\") if isinstance(x, dict) else None)\n",
    "df_divisions = df_divisions.dropna(subset=[\"total_votes\"])\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(6.0, 4.0))\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.hist(df_divisions[\"total_votes\"], bins=range(0, int(df_divisions[\"total_votes\"].max()) + 100, 100), edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Total Votes per Division\")\n",
    "plt.xlabel(\"Total Votes (binned by 100)\")\n",
    "plt.ylabel(\"Number of Divisions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure total_votes is extracted\n",
    "df_divisions[\"total_votes\"] = df_divisions[\"summary\"].apply(\n",
    "    lambda x: x.get(\"total_votes\") if isinstance(x, dict) else None\n",
    ")\n",
    "\n",
    "# Filter for high total_votes\n",
    "high_turnout = df_divisions[df_divisions[\"total_votes\"] > 15000]\n",
    "\n",
    "# Display result\n",
    "high_turnout[[\n",
    "    \"election_id\", \"council_id\", \"election_date\", \"division_name\", \"total_votes\", 'seats', \"status\", \"url\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf49465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by division_id and then by division_name\n",
    "grouped = df_divisions.groupby([\"division_id\", \"division_name\"]).agg({\n",
    "    \"election_id\": \"count\",\n",
    "    \"election_date\": \"min\",\n",
    "    \"total_votes\": \"mean\"\n",
    "}).rename(columns={\n",
    "    \"election_id\": \"num_elections\",\n",
    "    \"election_date\": \"first_election_date\",\n",
    "    \"total_votes\": \"avg_votes\"\n",
    "}).reset_index()\n",
    "\n",
    "# Sort by number of elections descending\n",
    "grouped_sorted = grouped.sort_values(by=\"num_elections\", ascending=False)\n",
    "\n",
    "# Show top results\n",
    "grouped_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = (\n",
    "    df_divisions\n",
    "    .groupby([\"council_id\", \"division_name\"], dropna=False)\n",
    "    .agg(\n",
    "        num_elections=(\"election_id\", \"count\"),\n",
    "        first_election_date=(\"election_date\", \"min\"),\n",
    "        last_election_date=(\"election_date\", \"max\"),\n",
    "        avg_votes=(\"summary\", lambda s: pd.Series([x.get(\"total_votes\") for x in s if x]).mean()),\n",
    "        example_url=(\"url\", \"first\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values([\"council_id\", \"division_name\"])\n",
    ")\n",
    "grouped.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782b7f3",
   "metadata": {},
   "source": [
    "#### Assigning proper division IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ca548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def slugify(name):\n",
    "    # Lowercase, replace & with \"and\", remove punctuation, replace spaces with underscores\n",
    "    slug = name.lower()\n",
    "    slug = re.sub(r\"[&]\", \"and\", slug)\n",
    "    slug = re.sub(r\"[^\\w\\s-]\", \"\", slug)  # remove punctuation\n",
    "    slug = re.sub(r\"[\\s]+\", \"_\", slug)    # replace spaces with underscores\n",
    "    return slug.strip(\"_\")\n",
    "\n",
    "# Apply to df_divisions\n",
    "df_divisions[\"division_uid\"] = df_divisions.apply(\n",
    "    lambda row: f\"{row['council_id']}__{slugify(row['division_name'])}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485c585",
   "metadata": {},
   "source": [
    "#### Assigning division code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f39d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort for stable ordering\n",
    "df_divisions = df_divisions.sort_values(by=[\"council_id\", \"division_name\"]).reset_index(drop=True)\n",
    "\n",
    "# Create numeric codes grouped by council_id\n",
    "df_divisions[\"division_code\"] = (\n",
    "    df_divisions.groupby(\"council_id\").cumcount() + 1\n",
    ").astype(str).str.zfill(3)  # e.g. 001, 002, ...\n",
    "\n",
    "# Add council prefix to make it unique\n",
    "df_divisions[\"division_code\"] = df_divisions[\"council_id\"].str.extract(r\"^([a-z]+)\")[0] + df_divisions[\"division_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871bfac",
   "metadata": {},
   "source": [
    "### Examining the candidate level of details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49465ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP: Extract candidates from each division ===\n",
    "candidate_records = []\n",
    "\n",
    "for _, row in df_divisions.iterrows():\n",
    "    for cand in row.get(\"candidates\", []):\n",
    "        candidate_records.append({\n",
    "            \"election_id\": row[\"election_id\"],\n",
    "            \"council_id\": row[\"council_id\"],\n",
    "            \"election_type\": row[\"election_type\"],\n",
    "            \"election_date\": row[\"election_date\"],\n",
    "            \"division_name\": row[\"division_name\"],\n",
    "            \"division_uid\": row[\"division_uid\"],\n",
    "            \"division_code\": row[\"division_code\"],\n",
    "            \"division_url\": row[\"url\"],\n",
    "            \"candidate_name\": cand.get(\"name\"),\n",
    "            \"party\": cand.get(\"party\"),\n",
    "            \"votes\": pd.to_numeric(cand.get(\"votes\"), errors=\"coerce\"),\n",
    "            \"percentage\": pd.to_numeric(str(cand.get(\"percentage\")).replace(\"%\", \"\"), errors=\"coerce\"),\n",
    "            \"outcome\": cand.get(\"outcome\")\n",
    "        })\n",
    "\n",
    "# === STEP: Convert to DataFrame ===\n",
    "df_candidates = pd.DataFrame(candidate_records)\n",
    "\n",
    "# === STEP: Preview ===\n",
    "print(f\"‚úÖ Loaded {len(df_candidates)} candidate records\")\n",
    "df_candidates.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88198d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[\"party\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65855424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map canonical name ‚Üí list of keywords to search for\n",
    "party_keywords = {\n",
    "    \"Labour\": [\"labour\"],\n",
    "    \"Conservatives\": [\"conservative\", \"tory\"],\n",
    "    \"Liberal Democrats\": [\"lib dem\", \"liberal democrat\", \"libdem\"],\n",
    "    \"Greens\": [\"green\"],\n",
    "    \"Reform UK\": [\"reform\"],\n",
    "    \"UKIP\": [\"ukip\", \"independence\", \"independance\"],\n",
    "    \"Women's Equality Party\": [\"women\"],\n",
    "    \"English Democrats\": [\"english democrat\"],\n",
    "    \"Tunbridge Wells Alliance\": [\"tunbridge wells\", \"t.w. alliance\"],\n",
    "    \"Ashford Independents\": [\"ashford independents\"],\n",
    "    \"Liberal\": [\"liberal\"],\n",
    "    \"Monster Raving Loony Party\": [\"monster raving\", \"mrp\", \"monster raving loony party\"],\n",
    "    \"National Front\": [\"national front\"], \n",
    "    \"People First\": [\"people first\"]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812951d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliases to catch less predictable patterns\n",
    "fallback_aliases = {\n",
    "    \"Labour\": [\"labour and co-operative\", \"co-operative and labour\"],\n",
    "    \"Liberal Democrats\": [\"the liberal democrats\"],\n",
    "    \"Independent\": [\"independent alliance\", \"local independent\", \"independent group\", \"Other\"],\n",
    "    \"Unknown\": [\"\", \"(no description)\", \"no description\", \"No description given\", \"No party specified\",None],\n",
    "}\n",
    "\n",
    "# Build lookup\n",
    "fallback_map = {\n",
    "    alias.lower(): canonical\n",
    "    for canonical, aliases in fallback_aliases.items()\n",
    "    for alias in aliases\n",
    "    if isinstance(alias, str)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e35da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_party(raw_party):\n",
    "    if not isinstance(raw_party, str):\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    raw_lower = raw_party.lower()\n",
    "\n",
    "    # Keyword search (robust first pass)\n",
    "    for canonical, keywords in party_keywords.items():\n",
    "        if any(keyword in raw_lower for keyword in keywords):\n",
    "            return canonical\n",
    "\n",
    "    # Fallback to exact alias matches\n",
    "    if raw_lower in fallback_map:\n",
    "        return fallback_map[raw_lower]\n",
    "\n",
    "    return raw_party.strip()  # return original if unclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[\"party_canonical\"] = df_candidates[\"party\"].apply(classify_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_minor = {\n",
    "    \"The Peace Party Non-Violence Jusitce, Environment\": \"The Peace Party\",\n",
    "    \"The Peace Party Non-Violence Justice, Environment\": \"The Peace Party\",\n",
    "    \"Trade Unionists and Socialists Against Cuts\": \"TUSC\",\n",
    "    \"Trade Unionist and Socialist Coalition\": \"TUSC\",\n",
    "    \"People First Party\": \"People First\",\n",
    "    \"Party for a United Thanet\": \"Thanet First\",\n",
    "    \"New England Party Caring for England\": \"New England Party\"\n",
    "}\n",
    "\n",
    "df_candidates[\"party_canonical\"] = df_candidates[\"party_canonical\"].replace(collapse_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[\"party_canonical\"].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e4969",
   "metadata": {},
   "source": [
    "### Create party IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === STEP 1: Clean and normalize names ===\n",
    "def clean_party_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return \"unknown\"\n",
    "    name = name.lower().strip()\n",
    "    name = re.sub(r\"\\bparty\\b$\", \"\", name).strip()  # Remove trailing \"party\"\n",
    "    return name\n",
    "\n",
    "def slugify(name):\n",
    "    name = clean_party_name(name)\n",
    "    name = re.sub(r\"[^\\w\\s-]\", \"\", name)       # Remove punctuation\n",
    "    name = re.sub(r\"\\s+\", \"_\", name)           # Replace whitespace with underscores\n",
    "    return name.strip(\"_\")\n",
    "\n",
    "# STEP 2: Count occurrences per canonical party\n",
    "party_counts = df_candidates[\"party_canonical\"].value_counts()\n",
    "\n",
    "# STEP 3: Reassign rare ones to 'Other'\n",
    "df_candidates[\"party_canonical\"] = df_candidates[\"party_canonical\"].apply(\n",
    "    lambda name: \"Other\" if party_counts.get(name, 0) < 2 else name\n",
    ")\n",
    "\n",
    "# STEP 4: Generate party_id\n",
    "df_candidates[\"party_id\"] = df_candidates[\"party_canonical\"].apply(\n",
    "    lambda x: f\"party_{slugify(x)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea68e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[\"party_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279ce8e7",
   "metadata": {},
   "source": [
    "to view elections with independent candidates - to verify no mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7341ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# ‚úÖ Safe re-merge of election_url only\n",
    "df_candidates = df_candidates.merge(\n",
    "    df[[\"election_id\", \"election_url\"]],\n",
    "    on=\"election_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# üéØ Filter for Independent candidates\n",
    "indep = df_candidates[df_candidates[\"party_canonical\"] == \"Independent\"]\n",
    "\n",
    "# üìÑ Create summary table\n",
    "table = (\n",
    "    indep[[\"election_id\", \"council_id\", \"election_url\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values([\"council_id\", \"election_id\"])\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# üîó Format clickable links\n",
    "table[\"link\"] = table[\"election_url\"].apply(\n",
    "    lambda url: f'<a href=\"{url}\" target=\"_blank\">view</a>' if pd.notna(url) else \"\"\n",
    ")\n",
    "\n",
    "# üìä Display the table as HTML (clickable)\n",
    "#display(HTML(table[[\"election_id\", \"council_id\", \"link\"]].to_html(escape=False, index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb80e9",
   "metadata": {},
   "source": [
    "### Cleaning candidates names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c289f",
   "metadata": {},
   "source": [
    "### Titles stripped, first and last name separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e69613",
   "metadata": {},
   "source": [
    "Strip titles and normalize names.\n",
    "\n",
    "Extract and store first_name, middle_names, last_name, and canonical_name.\n",
    "\n",
    "Identify potentially mergeable variants (e.g., ‚ÄúSteve Campkin‚Äù vs ‚ÄúSteven R Campkin‚Äù) ‚Äî but only where first names differ but share the same initial.\n",
    "\n",
    "applying all the transformations step-by-step to df_candidates, starting from candidate_name. This handles:\n",
    "\t1.\tStripping academic titles (MBE, OBE, etc)\n",
    "\t2.\tFixing commas and spacing\n",
    "\t3.\tFixing inverted names when the first token is ALL CAPS\n",
    "\t4.\tNormalizing casing\n",
    "\t5.\tSplitting into first_name, middle_names, last_name\n",
    "\t6.\tBuilding canonical_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# STEP 0 ‚Äî Sanitize obvious syntax issues\n",
    "df_candidates[\"candidate_name\"] = df_candidates[\"candidate_name\"].str.replace(\",,\", \",\", regex=False)\n",
    "\n",
    "# STEP 1 ‚Äî Start from raw names\n",
    "df_candidates[\"cleaned_candidate_name\"] = df_candidates[\"candidate_name\"].fillna(\"\").copy()\n",
    "\n",
    "df_candidates[\"candidate_name\"] = df_candidates[\"candidate_name\"].str.replace(r\"^(Mr|Mrs|Ms|Miss|Dr|Cllr|Sir|Dame)\\s+\", \"\", flags=re.IGNORECASE, regex=True)\n",
    "\n",
    "# STEP 2 ‚Äî Strip honorifics and degrees (MBE, PhD, etc)\n",
    "title_pattern = r\",?\\s+(MBE|OBE|CBE|KBE|DBE|CH|QC|KC|JP|DL|FRSA|FRICS|BA|MA|PhD|BSc|MSc|LLB|LLM|TD)\\b\"\n",
    "df_candidates[\"cleaned_candidate_name\"] = (\n",
    "    df_candidates[\"cleaned_candidate_name\"]\n",
    "    .str.replace(title_pattern, \"\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# STEP 3 ‚Äî Ensure comma is followed by a space (for proper splitting)\n",
    "df_candidates[\"cleaned_candidate_name\"] = df_candidates[\"cleaned_candidate_name\"].str.replace(r\",(?=\\S)\", \", \", regex=True)\n",
    "\n",
    "# STEP 4 ‚Äî Invert names if comma present (e.g. \"SMITH, John\" ‚Üí \"John Smith\")\n",
    "inverted_mask = df_candidates[\"cleaned_candidate_name\"].str.contains(\",\", na=False)\n",
    "df_candidates.loc[inverted_mask, \"cleaned_candidate_name\"] = (\n",
    "    df_candidates.loc[inverted_mask, \"cleaned_candidate_name\"]\n",
    "    .str.split(\",\", n=1)\n",
    "    .apply(lambda parts: f\"{parts[1].strip()} {parts[0].strip()}\" if len(parts) == 2 else parts[0])\n",
    ")\n",
    "# STEP 4b ‚Äî Invert names where the first token is ALL CAPS and others are not\n",
    "def conditional_invert(name):\n",
    "    tokens = name.strip().split()\n",
    "    if len(tokens) >= 2 and tokens[0].isupper() and not all(tok.isupper() for tok in tokens[1:]):\n",
    "        return \" \".join(tokens[1:] + [tokens[0].title()])\n",
    "    return name\n",
    "\n",
    "df_candidates[\"cleaned_candidate_name\"] = df_candidates[\"cleaned_candidate_name\"].apply(conditional_invert)\n",
    "\n",
    "# STEP 5 ‚Äî Convert all to title case\n",
    "df_candidates[\"cleaned_candidate_name\"] = df_candidates[\"cleaned_candidate_name\"].str.title().str.strip()\n",
    "\n",
    "# STEP 5b ‚Äî Fix McX and MacX capitalisation (e.g., Mcdonald ‚Üí McDonald, Macpherson ‚Üí MacPherson)\n",
    "df_candidates[\"cleaned_candidate_name\"] = df_candidates[\"cleaned_candidate_name\"].str.replace(\n",
    "    r\"\\b(Mc|Mac)([a-z])\",\n",
    "    lambda m: m.group(1) + m.group(2).upper(),\n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# STEP 6 ‚Äî Split into first / middle / last\n",
    "split_parts = df_candidates[\"cleaned_candidate_name\"].str.split()\n",
    "df_candidates[\"first_name\"] = split_parts.apply(lambda x: x[0] if len(x) > 0 else \"\")\n",
    "df_candidates[\"last_name\"] = split_parts.apply(lambda x: x[-1] if len(x) > 1 else \"\")\n",
    "df_candidates[\"middle_names\"] = split_parts.apply(lambda x: \" \".join(x[1:-1]) if len(x) > 2 else \"\")\n",
    "\n",
    "# STEP 7 ‚Äî Construct canonical name: First + Last\n",
    "df_candidates[\"canonical_name\"] = (\n",
    "    df_candidates[\"first_name\"].str.strip() + \" \" + df_candidates[\"last_name\"].str.strip()\n",
    ").str.strip()\n",
    "\n",
    "# STEP 8 ‚Äî Final tidy-up: remove stray trailing commas\n",
    "df_candidates[\"canonical_name\"] = df_candidates[\"canonical_name\"].str.rstrip(\",\").str.strip()\n",
    "df_candidates[\"last_name\"] = df_candidates[\"last_name\"].str.rstrip(\",\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f07b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where the first_name ends with a comma\n",
    "mask = df_candidates[\"first_name\"].str.endswith(\",\", na=False)\n",
    "\n",
    "# Display problematic rows for inspection\n",
    "df_candidates.loc[mask, [\"candidate_name\", \"cleaned_candidate_name\", \"first_name\", \"middle_names\", \"last_name\", \"canonical_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d281b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_candidates[\"candidate_name\"] == \"R. John Pritchard\"\n",
    "\n",
    "# Override cleaned fields\n",
    "df_candidates.loc[mask, \"cleaned_candidate_name\"] = \"John Pritchard\"\n",
    "df_candidates.loc[mask, \"first_name\"] = \"John\"\n",
    "df_candidates.loc[mask, \"middle_names\"] = \"R\"\n",
    "df_candidates.loc[mask, \"last_name\"] = \"Pritchard\"\n",
    "df_candidates.loc[mask, \"canonical_name\"] = \"John Pritchard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a738618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8 ‚Äî Final diagnostic view\n",
    "df_candidates[[\"candidate_name\", \"cleaned_candidate_name\", \"first_name\", \"middle_names\", \"last_name\", \"canonical_name\"]].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[df_candidates[\"first_name\"].str.isupper() & df_candidates[\"first_name\"].str.len() > 1][\n",
    "    [\"candidate_name\", \"cleaned_candidate_name\", \"first_name\", \"last_name\", \"canonical_name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae21029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[df_candidates[\"last_name\"].str.islower()][\n",
    "    [\"candidate_name\", \"cleaned_candidate_name\", \"first_name\", \"last_name\", \"canonical_name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636db3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[df_candidates[\"canonical_name\"].str.split().str.len() > 2][\n",
    "    [\"candidate_name\", \"canonical_name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates['canonical_name'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60307ae6",
   "metadata": {},
   "source": [
    "#### Assign councillor status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates[\"is_councillor\"] = df_candidates[\"outcome\"].str.lower() == \"elected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28896780",
   "metadata": {},
   "source": [
    "### Canonical Name Mapping and Normalisation\n",
    "\n",
    "This code below refines candidate name consistency across election records:\n",
    "\n",
    "- **Exclusions**: A predefined list of merge-excluded indices (`excluded_merge_indices`) identifies ambiguous last names that should not be merged.\n",
    "- **Group and Merge**: For each last name in `last_name_map`, candidate full names are grouped by first name. If all first names share the same initial, the longest variant is chosen as the canonical name.\n",
    "- **Exception Handling**: If a last name is in the exclusion list, all its variants are kept separate.\n",
    "- **Assignment**: The `canonical_name` field is assigned to each candidate in the dataset based on the mapping.\n",
    "- **Diagnostics**: A list (`diffs`) shows where original names differ from canonical ones for inspection.\n",
    "\n",
    "This helps unify inconsistent name formats (e.g. \"J. Smith\", \"John Smith\", \"Jonathan Smith\") while allowing manual override of ambiguous cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233626ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rebuild Ambiguity Map ===\n",
    "from collections import defaultdict\n",
    "\n",
    "df_candidates[\"stripped_name\"] = df_candidates[\"candidate_name\"].fillna(\"\").apply(strip_titles)\n",
    "\n",
    "last_name_map = defaultdict(set)\n",
    "for _, row in df_candidates.iterrows():\n",
    "    first, middle, last = row[\"first_name\"], row[\"middle_names\"], row[\"last_name\"]\n",
    "    full = row[\"stripped_name\"]\n",
    "    if first and last:\n",
    "        last_name_map[last].add((first, middle, full))\n",
    "\n",
    "# === Detect ambiguous last names ===\n",
    "ambiguous_last_names = {}\n",
    "\n",
    "for last, entries in last_name_map.items():\n",
    "    first_names = {first for first, _, _ in entries if first}\n",
    "    first_initials = {first[0] for first in first_names}\n",
    "    if len(first_names) > 1 and len(first_initials) == 1:\n",
    "        ambiguous_last_names[last] = sorted(entries)\n",
    "\n",
    "# === Convert to DataFrame for inspection ===\n",
    "ambiguous_df = pd.DataFrame([\n",
    "    {\n",
    "        \"last_name\": last,\n",
    "        \"first_names\": \", \".join(sorted({first for first, _, _ in entries})),\n",
    "        \"examples\": \"; \".join(sorted(full for _, _, full in entries))\n",
    "    }\n",
    "    for last, entries in ambiguous_last_names.items()\n",
    "])\n",
    "\n",
    "# === View result ===\n",
    "ambiguous_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b75d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show candidates where the name or last name contains \"Winterbottom\"\n",
    "mask = (\n",
    "    df_candidates[\"candidate_name\"].str.contains(\"sue\", case=False, na=False) |\n",
    "    df_candidates[\"last_name\"].str.contains(\"sue\", case=False, na=False)\n",
    ")\n",
    "\n",
    "# Display relevant columns for review\n",
    "df_candidates.loc[mask, [\"candidate_name\", \"cleaned_candidate_name\", \"first_name\", \"middle_names\", \"last_name\", \"canonical_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281543c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_candidates[\"candidate_name\"] == \"Bell Sue\"\n",
    "\n",
    "# Override cleaned fields\n",
    "df_candidates.loc[mask, \"cleaned_candidate_name\"] = \"Sue Bell\"\n",
    "df_candidates.loc[mask, \"first_name\"] = \"Sue\"\n",
    "df_candidates.loc[mask, \"middle_names\"] = \"\"\n",
    "df_candidates.loc[mask, \"last_name\"] = \"Bell\"\n",
    "df_candidates.loc[mask, \"canonical_name\"] = \"Sue Bell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_candidates[\"candidate_name\"] == \"Butterfield Sue\"\n",
    "\n",
    "# Override cleaned fields\n",
    "df_candidates.loc[mask, \"cleaned_candidate_name\"] = \"Sue Butterfill\"\n",
    "df_candidates.loc[mask, \"first_name\"] = \"Sue\"\n",
    "df_candidates.loc[mask, \"middle_names\"] = \"\"\n",
    "df_candidates.loc[mask, \"last_name\"] = \"Butterfill\"\n",
    "df_candidates.loc[mask, \"canonical_name\"] = \"Sue Butterfill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50566a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_candidates[\"candidate_name\"] == \"Sue Butterfield\"\n",
    "\n",
    "# Override cleaned fields\n",
    "df_candidates.loc[mask, \"cleaned_candidate_name\"] = \"Sue Butterfield\"\n",
    "df_candidates.loc[mask, \"first_name\"] = \"Sue\"\n",
    "df_candidates.loc[mask, \"middle_names\"] = \"\"\n",
    "df_candidates.loc[mask, \"last_name\"] = \"Butterfield\"\n",
    "df_candidates.loc[mask, \"canonical_name\"] = \"Sue Butterfield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_candidates[\"candidate_name\"] == \"Eykelenboom Katherine Ann\"\n",
    "\n",
    "# Override cleaned fields\n",
    "df_candidates.loc[mask, \"cleaned_candidate_name\"] = \"Katherine Ann Eykelenboom\"\n",
    "df_candidates.loc[mask, \"first_name\"] = \"Katherine\"\n",
    "df_candidates.loc[mask, \"middle_names\"] = \"Ann\"\n",
    "df_candidates.loc[mask, \"last_name\"] = \"Eykelenboom\"\n",
    "df_candidates.loc[mask, \"canonical_name\"] = \"Katherine Eykelenboom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_candidates[\"candidate_name\"] == \"Winterbottom Kim\"\n",
    "\n",
    "# Override cleaned fields\n",
    "df_candidates.loc[mask, \"cleaned_candidate_name\"] = \"Kim Winterbottom\"\n",
    "df_candidates.loc[mask, \"first_name\"] = \"Kim\"\n",
    "df_candidates.loc[mask, \"middle_names\"] = \"\"\n",
    "df_candidates.loc[mask, \"last_name\"] = \"Winterbottom\"\n",
    "df_candidates.loc[mask, \"canonical_name\"] = \"Kim Winterbottom\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248fd350",
   "metadata": {},
   "source": [
    "‚úÖ Guidelines to Exclude\n",
    "\n",
    "You should exclude any row where:\n",
    "\n",
    "    The first names differ in gender (e.g., Teresa and Tom)\n",
    "\n",
    "    The names are clearly distinct (e.g., James and John)\n",
    "\n",
    "    There is no strong reason to assume they're variants of the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_merge_indices = [\n",
    "    1,   # Grayling ‚Üí Chris vs Christopher ‚Äî likely same but borderline\n",
    "    2,   # Pickering ‚Üí Alan vs Audrey ‚Äî different gender\n",
    "#    5,   # Chattenton ‚Üí Jeremy vs Jerry ‚Äî possible, but Jerry not a standard Jeremy nickname\n",
    "    6,   # Benford ‚Üí Margaret vs Marian ‚Äî different names\n",
    "#    10,  # Barnett ‚Üí Rosa vs Rosetta ‚Äî possibly different people\n",
    "    12,  # Ozog ‚Üí Jan vs Julie ‚Äî different names and likely different gender\n",
    "    13,  # Dunmall ‚Üí Chris vs Christine ‚Äî gender mismatch\n",
    "    14,  # Lawson ‚Üí David vs Derek ‚Äî different names\n",
    "#    15,  # Bobby ‚Üí Les vs Leslie ‚Äî possibly same, but could be male/female versions\n",
    "    17,  # Lynch ‚Üí Karen vs Katie ‚Äî not clear they‚Äôre the same\n",
    "    19,  # Withstandley ‚Üí Barbara vs Brian ‚Äî definitely different\n",
    "    20,  # Binks ‚Üí Roger vs Rosalind ‚Äî definitely different\n",
    "    21,  # Matterface ‚Üí Jennifer vs Jenny vs John ‚Äî gender and identity ambiguity\n",
    "#    31,  # Shread ‚Üí Nick vs Nicolas ‚Äî might be same but if both appear, best to be safe\n",
    "    32,  # Moss ‚Üí Benjamin vs Brian ‚Äî different names\n",
    "    34,  # Meade ‚Üí Jackie vs Jordan ‚Äî very different names\n",
    "    35,  # Hodge ‚Üí Sarah vs Susan ‚Äî clearly distinct\n",
    "    36,  # Beer ‚Üí James, Jon, Julia ‚Äî mixed gender and unrelated names\n",
    "    40,  # Slaughter ‚Üí Rachel vs Ryan ‚Äî different gender\n",
    "    42,  # Lack ‚Üí Maggie vs Martin ‚Äî different gender\n",
    "#    43,  # Summersgill ‚Üí Michael vs Mick vs Mike ‚Äî possibly same, but if all exist maybe split\n",
    "    47,  # London ‚Üí James vs John ‚Äî commonly confused but different\n",
    "\n",
    "    73,  # Brindle ‚Üí Adrian vs Anne ‚Äî different gender\n",
    "    78,  # Underwood ‚Üí Patricia vs Peter ‚Äî gender mismatch\n",
    "    85,  # Nuttall ‚Üí Sue vs Susan ‚Äî same root, but may be different people\n",
    "    88,  # Fowle ‚Üí Sandra vs Simon ‚Äî gender mismatch\n",
    "    96,  # Sue ‚Üí Bell vs Butterfield ‚Äî last name Sue is actually the first name\n",
    "    97,  # O'Toole ‚Üí Lee vs Liam ‚Äî likely different people\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242a1c2",
   "metadata": {},
   "source": [
    "This code block identifies ambiguous last names where multiple first names share the same initial (e.g. *Steve* and *Steven* Campkin), then applies a canonical naming rule:\n",
    "\n",
    "* It **merges** those names only if not manually excluded,\n",
    "* And assigns the **longest full version** of each name as canonical.\n",
    "\n",
    "It ensures consistency in tracking people across elections without incorrectly combining distinct individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Get last names from excluded rows in the previously built ambiguous_df\n",
    "excluded_last_names = rechecked_strict_df.loc[excluded_merge_indices, \"last_name\"].tolist()\n",
    "\n",
    "# Add special override for partial merging within ambiguous last names\n",
    "partial_merge_overrides = {\n",
    "    \"Matterface\": {\n",
    "        # group these first names into one canonical group\n",
    "        \"Jennifer\": [\"Jenny\", \"Jennifer\"]\n",
    "        # leave \"John\" out ‚Äî it will be handled separately\n",
    "    }\n",
    "}\n",
    "\n",
    "# Rebuild canonical name map with partial merges\n",
    "final_canonical_name_map = {}\n",
    "\n",
    "for last, entries in last_name_map.items():\n",
    "    grouped_by_first = defaultdict(list)\n",
    "    first_initials = set()\n",
    "\n",
    "    for first, middle, full in entries:\n",
    "        if first:\n",
    "            grouped_by_first[first].append(full)\n",
    "            first_initials.add(first[0])\n",
    "\n",
    "    if last in partial_merge_overrides:\n",
    "        # Merge only within specified subgroups\n",
    "        overrides = partial_merge_overrides[last]\n",
    "        handled = set()\n",
    "\n",
    "        for canonical, first_variants in overrides.items():\n",
    "            merged_variants = []\n",
    "            for first in first_variants:\n",
    "                merged_variants.extend(grouped_by_first.pop(first, []))\n",
    "                handled.add(first)\n",
    "\n",
    "            # Pick the longest as representative\n",
    "            if merged_variants:\n",
    "                canonical_variant = max(merged_variants, key=len)\n",
    "                for v in merged_variants:\n",
    "                    final_canonical_name_map[(canonical, last)] = canonical_variant\n",
    "\n",
    "        # All other unmerged first names (like 'John') ‚Üí treat as separate\n",
    "        for first, variants in grouped_by_first.items():\n",
    "            for v in variants:\n",
    "                final_canonical_name_map[(first.strip(), last.strip())] = v\n",
    "\n",
    "    elif last in excluded_last_names:\n",
    "        # Fully excluded ‚Üí treat each first name separately\n",
    "        for first, variants in grouped_by_first.items():\n",
    "            for v in variants:\n",
    "                final_canonical_name_map[(first.strip(), last.strip())] = v\n",
    "\n",
    "    elif len(first_initials) == 1:\n",
    "        # Safe to merge all\n",
    "        for first, variants in grouped_by_first.items():\n",
    "            canonical_variant = max(variants, key=len)\n",
    "            for v in variants:\n",
    "                final_canonical_name_map[(first.strip(), last.strip())] = canonical_variant\n",
    "\n",
    "            \n",
    "# ‚úÖ Apply final canonical name mapping to df_candidates\n",
    "\n",
    "def apply_canonical(row):\n",
    "    key = (row[\"first_name\"].strip(), row[\"last_name\"].strip())\n",
    "    return final_canonical_name_map.get(key, row[\"candidate_name\"])\n",
    "\n",
    "# Create new column with cleaned names\n",
    "df_candidates[\"canonical_name\"] = df_candidates.apply(apply_canonical, axis=1)\n",
    "\n",
    "# üîç Show examples of standardised names\n",
    "diffs = df_candidates[df_candidates[\"candidate_name\"] != df_candidates[\"canonical_name\"]][\n",
    "    [\"candidate_name\", \"canonical_name\"]\n",
    "].drop_duplicates().sort_values(by=\"candidate_name\")\n",
    "\n",
    "print(f\"‚úÖ {len(diffs)} candidate names were standardised.\\n\")\n",
    "display(diffs.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a093813",
   "metadata": {},
   "source": [
    "This is a last-mile cleaning patch. It:\n",
    "\n",
    "    Fixes known typos (e.g., \"Joesph\" ‚Üí \"Joseph\")\n",
    "\n",
    "    Removes double spaces and trailing whitespace\n",
    "\n",
    "    Updates canonical_name fields if they differ from the cleaned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fabd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom cleaning script for diffs \n",
    " \n",
    "import re\n",
    "\n",
    "def clean_canonical_name(name):\n",
    "    # Fix common typos\n",
    "    name = name.replace(\"Joesph\", \"Joseph\")\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    name = re.sub(r\"\\s{2,}\", \" \", name)\n",
    "\n",
    "    # Strip and standardise spacing\n",
    "    return name.strip()\n",
    "\n",
    "# Apply cleanup\n",
    "cleaned_diffs = sorted({\n",
    "    (orig, clean_canonical_name(canon))\n",
    "    for orig, canon in diffs\n",
    "    if orig != clean_canonical_name(canon)  # Only include cleaned diffs\n",
    "})\n",
    "\n",
    "# Optional: update canonical names directly in your data\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    for cand in record[\"candidates\"]:\n",
    "        orig = cand.get(\"name\", \"\")\n",
    "        canon = cand.get(\"canonical_name\", \"\")\n",
    "        cleaned = clean_canonical_name(canon)\n",
    "        if orig != cleaned:\n",
    "            cand[\"canonical_name\"] = cleaned\n",
    "\n",
    "# Preview cleaned diffs\n",
    "cleaned_diffs[:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d92780",
   "metadata": {},
   "source": [
    "### Code: Flag Shared Last Names Across Different People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Build a map of last name ‚Üí set of full canonical names\n",
    "last_name_to_people = defaultdict(set)\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    for cand in record[\"candidates\"]:\n",
    "        last = cand.get(\"last_name\", \"\").strip()\n",
    "        canon = cand.get(\"canonical_name\", \"\").strip()\n",
    "        if last and canon:\n",
    "            last_name_to_people[last].add(canon)\n",
    "\n",
    "# Filter to only those last names that have >1 distinct person\n",
    "ambiguous_last_names = {\n",
    "    last: sorted(list(people))\n",
    "    for last, people in last_name_to_people.items()\n",
    "    if len(people) > 1\n",
    "}\n",
    "\n",
    "# Display\n",
    "for last, names in sorted(ambiguous_last_names.items()):\n",
    "    print(f\"‚ö†Ô∏è  Shared last name: {last}\")\n",
    "    for name in names:\n",
    "        print(f\"   - {name}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043847cb",
   "metadata": {},
   "source": [
    "### Create aliases commonly used in council documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "nicknames = {\n",
    "    # Male names\n",
    "    \"Christopher\": \"Chris\",\n",
    "    \"Jonathan\": \"Jon\",\n",
    "    \"Stephen\": \"Steve\",\n",
    "    \"Steven\": \"Steve\",\n",
    "    \"Michael\": \"Mike\",\n",
    "    \"Richard\": \"Rick\",\n",
    "    \"Robert\": \"Rob\",\n",
    "    \"Joseph\": \"Joe\",\n",
    "    \"Timothy\": \"Tim\",\n",
    "    \"Nicholas\": \"Nick\",\n",
    "    \"James\": \"Jim\",\n",
    "    \"Francis\": \"Frank\",\n",
    "    \"Jeremy\": \"Jerry\",\n",
    "\n",
    "    # Female names\n",
    "    \"Margaret\": \"Maggie\",\n",
    "    \"Elizabeth\": \"Liz\",\n",
    "    \"Patricia\": \"Pat\",\n",
    "    \"Penelope\": \"Penny\",\n",
    "    \"Pamela\": \"Pam\",\n",
    "    \"Karen\": \"Kate\",  # or Katie\n",
    "    \"Katherine\": \"Kate\",\n",
    "    \"Rebecca\": \"Becky\",\n",
    "    \"Deborah\": \"Debbie\",\n",
    "    \"Susan\": \"Sue\",\n",
    "    \"Jacqueline\": \"Jackie\",\n",
    "    \"Victoria\": \"Vicky\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_initials(full_name, last_name):\n",
    "    \"\"\"Extract initials from full name, skipping the last name.\"\"\"\n",
    "    parts = full_name.replace(last_name, \"\").strip().split()\n",
    "    return [p[0] for p in parts if p and p[0].isalpha()]\n",
    "\n",
    "def generate_aliases(first_name, last_name, canonical_name):\n",
    "    aliases = set()\n",
    "\n",
    "    # Title-based forms (all genders)\n",
    "    for title in [\"Mr\", \"Ms\", \"Mrs\", \"Miss\", \"Cllr\", \"Councillor\"]:\n",
    "        aliases.add(f\"{title} {last_name}\")\n",
    "\n",
    "    # Add full first name + last name\n",
    "    if first_name:\n",
    "        aliases.add(f\"{first_name} {last_name}\")\n",
    "        aliases.add(f\"{first_name[0]} {last_name}\")\n",
    "\n",
    "    # Extract canonical first name (may be more formal)\n",
    "    canonical_first = canonical_name.split()[0]\n",
    "    if canonical_first.lower() != first_name.lower():\n",
    "        aliases.add(f\"{canonical_first} {last_name}\")\n",
    "\n",
    "    # Add nickname if available\n",
    "    nick = nicknames.get(canonical_first)\n",
    "    if nick and nick.lower() != first_name.lower():\n",
    "        aliases.add(f\"{nick} {last_name}\")\n",
    "\n",
    "    # Add initials\n",
    "    initials = extract_initials(canonical_name, last_name)\n",
    "    if initials:\n",
    "        joined = ' '.join(initials)\n",
    "        for title in [\"Mr\", \"Ms\", \"Mrs\", \"Miss\"]:\n",
    "            aliases.add(f\"{title} {joined} {last_name}\")\n",
    "            aliases.add(f\"{title}\\n{joined} {last_name}\")\n",
    "        aliases.add(f\"{joined} {last_name}\")\n",
    "\n",
    "    return sorted(aliases)\n",
    "\n",
    "\n",
    "# === Apply to your data ===\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    for cand in record[\"candidates\"]:\n",
    "        first = cand.get(\"first_name\", \"\").strip()\n",
    "        last = cand.get(\"last_name\", \"\").strip()\n",
    "        canon = cand.get(\"canonical_name\", cand.get(\"name\", \"\")).strip()\n",
    "        cand[\"aliases\"] = generate_aliases(first, last, canon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac97b1a",
   "metadata": {},
   "source": [
    "What code below does\n",
    "\n",
    "    Keeps the preferred version of each (date, candidate) pair\n",
    "\n",
    "    Drops any duplicate where the division name starts with \"County\"\n",
    "\n",
    "    Leaves you with one clean record per candidate per date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89405430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Keyed by (election_date, canonical_name)\n",
    "deduped_records = {}\n",
    "skipped_records = []\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    election_date = record.get(\"election_date\")\n",
    "    division = record.get(\"division\", \"\").strip()\n",
    "    url = record.get(\"url\", \"\")\n",
    "\n",
    "    for cand in record.get(\"candidates\", []):\n",
    "        name = cand.get(\"canonical_name\", \"\").strip()\n",
    "        key = (election_date, name)\n",
    "\n",
    "        # Prefer division NOT starting with 'County'\n",
    "        keep_current = not division.lower().startswith(\"county council\")\n",
    "\n",
    "        if key not in deduped_records:\n",
    "            deduped_records[key] = {\n",
    "                \"record\": record,\n",
    "                \"candidate\": cand,\n",
    "                \"division\": division\n",
    "            }\n",
    "        else:\n",
    "            existing_div = deduped_records[key][\"division\"]\n",
    "            if keep_current and existing_div.lower().startswith(\"county council\"):\n",
    "                deduped_records[key] = {\n",
    "                    \"record\": record,\n",
    "                    \"candidate\": cand,\n",
    "                    \"division\": division\n",
    "                }\n",
    "            else:\n",
    "                skipped_records.append((name, election_date, division))\n",
    "\n",
    "# Build deduplicated version\n",
    "deduplicated_data = []\n",
    "for (date, name), info in deduped_records.items():\n",
    "    record = info[\"record\"].copy()\n",
    "    record[\"candidates\"] = [info[\"candidate\"]]\n",
    "    deduplicated_data.append(record)\n",
    "\n",
    "# Replace your working data\n",
    "print(f\"‚úÖ Deduplicated dataset: {len(data)} ‚Üí {len(deduplicated_data)} records\")\n",
    "data = deduplicated_data\n",
    "\n",
    "# Optional: View what was skipped\n",
    "if skipped_records:\n",
    "    print(f\"üóëÔ∏è Skipped {len(skipped_records)} duplicate entries (less preferred divisions):\")\n",
    "    for name, date, div in skipped_records[:10]:\n",
    "        print(f\"- {name} on {date} in '{div}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28168b54",
   "metadata": {},
   "source": [
    "### Creating unique persons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure `canonical_name` and election date exist\n",
    "assert \"canonical_name\" in df_candidates.columns\n",
    "assert \"election_date\" in df_candidates.columns\n",
    "\n",
    "df_candidates[\"is_councillor\"] = df_candidates[\"outcome\"].str.lower() == \"elected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313179ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to prioritise most recent elections\n",
    "df_c = df_candidates.sort_values(\"election_date\")\n",
    "\n",
    "# Group by canonical name and keep the most recent record (or earliest if you prefer)\n",
    "df_people = (\n",
    "    df_c.groupby(\"canonical_name\")\n",
    "    .agg({\n",
    "        \"election_date\": lambda x: x[df_c.loc[x.index, \"is_councillor\"]].min(),  # first elected date\n",
    "        \"party_canonical\": \"last\",\n",
    "        \"council_id\": \"last\",\n",
    "    })\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = df_people.sort_values(\"canonical_name\").reset_index(drop=True)\n",
    "df_people[\"person_id\"] = df_people.index.map(lambda i: f\"person_{i+1:04d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86389ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = df_people[\n",
    "    [\"person_id\", \"canonical_name\", \"election_date\", \"party_canonical\", \"council_id\"]\n",
    "].rename(columns={\"election_date\": \"first_elected_date\", \"party_canonical\": \"party\"})\n",
    "\n",
    "df_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507caf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üìä Records remaining in data: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fccc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/elections/kent_results_all_years_cleaned.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for record in data:\n",
    "        json.dump(record, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed9537",
   "metadata": {},
   "source": [
    "### Examine one person- Candidate Participation Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def get_candidate_history(data, candidate_name):\n",
    "    records = []\n",
    "\n",
    "    for record in data:\n",
    "        if record.get(\"status\") != \"ok\":\n",
    "            continue\n",
    "        date = record.get(\"election_date\")\n",
    "        div = record.get(\"division\", \"\")\n",
    "        election_type = record.get(\"election_type\", \"unknown\")\n",
    "        url = record.get(\"url\", \"\")\n",
    "        for cand in record.get(\"candidates\", []):\n",
    "            if cand.get(\"canonical_name\", \"\").strip() == candidate_name:\n",
    "                records.append({\n",
    "                    \"Election Date\": date,\n",
    "                    \"Division\": div,\n",
    "                    \"Party\": cand.get(\"party\", \"\"),\n",
    "                    \"Outcome\": cand.get(\"outcome\", \"\"),\n",
    "                    \"Election Type\": election_type,\n",
    "                    \"URL\": f'<a href=\"{url}\" target=\"_blank\">Link</a>'\n",
    "                })\n",
    "\n",
    "    if not records:\n",
    "        print(f\"‚ö†Ô∏è No records found for: {candidate_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(sorted(records, key=lambda x: x[\"Election Date\"]))\n",
    "    return df.to_html(escape=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d832259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Trevor Shonk's election history as clickable table\n",
    "html_table = get_candidate_history(data, \"Trevor Leslie Shonk\")\n",
    "display(HTML(html_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b5ff7d",
   "metadata": {},
   "source": [
    "### Crosstab of election results - by party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# === Load and patch the data ===\n",
    "data = []\n",
    "with open(\"../data/elections/kent_results_all_years_cleaned.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        # Patch: If 'election_date' is missing, extract from 'division'\n",
    "        if entry.get(\"status\") == \"ok\" and \"election_date\" not in entry:\n",
    "            division = entry.get(\"division\", \"\")\n",
    "            if \",\" in division:\n",
    "                try:\n",
    "                    possible_date = division.split(\",\")[-1].strip()\n",
    "                    parsed_date = datetime.strptime(possible_date, \"%d/%m/%Y\").date()\n",
    "                    entry[\"election_date\"] = str(parsed_date)\n",
    "                except ValueError:\n",
    "                    pass  # Skip if date can't be parsed\n",
    "\n",
    "        data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which 'ok' entries are missing 'election_date'\n",
    "missing_dates = [entry for entry in data if entry.get(\"status\") == \"ok\" and \"election_date\" not in entry]\n",
    "print(f\"‚ö†Ô∏è Entries missing 'election_date': {len(missing_dates)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b586bd",
   "metadata": {},
   "source": [
    "### Reform candidates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d90987",
   "metadata": {},
   "source": [
    "the table produced below:\n",
    "\n",
    "The final df is a timeline matrix of candidates whose latest party is \"Reform UK\", showing:\n",
    "\n",
    "| Row ‚Üí each Reform UK candidate's canonical_name\n",
    "| Columns ‚Üí regular election dates (election_date)\n",
    "| Cell value ‚Üí election outcome at that date\n",
    "| Plus one column: Latest Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c820a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 0: Filter regular elections only for timeline columns\n",
    "election_dates = sorted({\n",
    "    entry[\"election_date\"]\n",
    "    for entry in data\n",
    "    if entry.get(\"status\") == \"ok\" and entry.get(\"election_type\") == \"regular\"\n",
    "})\n",
    "\n",
    "# Step 1: Track latest party for each candidate by canonical name\n",
    "latest_party_by_candidate = {}\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    election_date = record[\"election_date\"]\n",
    "    for cand in record[\"candidates\"]:\n",
    "        name = cand[\"canonical_name\"].strip()\n",
    "        if name not in latest_party_by_candidate or election_date > latest_party_by_candidate[name][\"election_date\"]:\n",
    "            latest_party_by_candidate[name] = {\n",
    "                \"election_date\": election_date,\n",
    "                \"party\": cand[\"party\"]\n",
    "            }\n",
    "\n",
    "# Step 2: Build outcome timeline for candidates whose latest party is \"Reform UK\"\n",
    "party_filter = \"Reform UK\"\n",
    "candidate_results = defaultdict(lambda: {date: \"NP\" for date in election_dates})\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    election_date = record[\"election_date\"]\n",
    "    if election_date not in election_dates:\n",
    "        continue  # skip byelections\n",
    "    for cand in record[\"candidates\"]:\n",
    "        name = cand[\"canonical_name\"].strip()\n",
    "        if latest_party_by_candidate.get(name, {}).get(\"party\") == party_filter:\n",
    "            candidate_results[name][election_date] = cand[\"outcome\"]\n",
    "\n",
    "# Step 3: Convert to DataFrame\n",
    "df = pd.DataFrame.from_dict(candidate_results, orient=\"index\")\n",
    "df.index.name = \"Candidate\"\n",
    "\n",
    "# Step 4: Add each candidate's latest division\n",
    "latest_division_by_candidate = {}\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    election_date = record[\"election_date\"]\n",
    "    division = record[\"division\"]\n",
    "    for cand in record[\"candidates\"]:\n",
    "        name = cand[\"canonical_name\"].strip()\n",
    "        if name not in latest_division_by_candidate or election_date > latest_division_by_candidate[name][\"election_date\"]:\n",
    "            latest_division_by_candidate[name] = {\n",
    "                \"election_date\": election_date,\n",
    "                \"division\": division\n",
    "            }\n",
    "\n",
    "df[\"Latest Division\"] = df.index.map(lambda name: latest_division_by_candidate.get(name, {}).get(\"division\", \"\"))\n",
    "\n",
    "# Reorder columns\n",
    "df = df[[\"Latest Division\"] + [col for col in df.columns if col != \"Latest Division\"]]\n",
    "\n",
    "# View the result\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae098f7",
   "metadata": {},
   "source": [
    "### Councillors elected in 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94913985",
   "metadata": {},
   "source": [
    "The final councillor_df is a comprehensive performance and history profile for all councillors elected in the most recent regular election. It captures their past results, experience, party affiliations, and division in one clean table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the most recent election date\n",
    "latest_election_date = max(election_dates)\n",
    "\n",
    "# Step 2: Find all candidates elected in the latest election\n",
    "elected_councillors = set()\n",
    "latest_division_by_candidate = {}\n",
    "latest_party_by_candidate = {}\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    if record[\"election_date\"] != latest_election_date:\n",
    "        continue\n",
    "\n",
    "    division = record[\"division\"]\n",
    "    for cand in record[\"candidates\"]:\n",
    "        if cand[\"outcome\"] == \"Elected\":\n",
    "            name = cand[\"canonical_name\"].strip()\n",
    "            elected_councillors.add(name)\n",
    "            latest_division_by_candidate[name] = division\n",
    "            latest_party_by_candidate[name] = cand[\"party\"]\n",
    "\n",
    "# Build party history for each candidate\n",
    "party_affiliations_by_candidate = defaultdict(set)\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    for cand in record[\"candidates\"]:\n",
    "        name = cand[\"canonical_name\"].strip()\n",
    "        party = cand[\"party\"].strip()\n",
    "        if name and party:\n",
    "            party_affiliations_by_candidate[name].add(party)\n",
    "\n",
    "\n",
    "# Step 3: Build the outcome history for each elected councillor\n",
    "councillor_results = defaultdict(lambda: {date: \"NP\" for date in election_dates})\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    election_date = record[\"election_date\"]\n",
    "    for cand in record[\"candidates\"]:\n",
    "        name = cand[\"canonical_name\"].strip()\n",
    "        if name in elected_councillors:\n",
    "            councillor_results[name][election_date] = cand[\"outcome\"]\n",
    "\n",
    "# Step 4: Create DataFrame\n",
    "councillor_df = pd.DataFrame.from_dict(councillor_results, orient=\"index\")\n",
    "councillor_df.index.name = \"Councillor\"\n",
    "\n",
    "# Add division and latest party columns\n",
    "councillor_df[\"Division\"] = councillor_df.index.map(lambda name: latest_division_by_candidate.get(name, \"\"))\n",
    "councillor_df[\"Latest Party\"] = councillor_df.index.map(lambda name: latest_party_by_candidate.get(name, \"\"))\n",
    "\n",
    "# Reorder columns\n",
    "cols = [\"Division\", \"Latest Party\"] + [col for col in election_dates]\n",
    "councillor_df = councillor_df[cols]\n",
    "\n",
    "# Filter the DataFrame to include only councillors who were elected in the latest election\n",
    "elected_df = councillor_df[councillor_df[latest_election_date] == \"Elected\"]\n",
    "# Step 1: Format past parties (already done above)\n",
    "councillor_df[\"Past Parties\"] = councillor_df.index.map(\n",
    "    lambda name: \", \".join(sorted(party_affiliations_by_candidate.get(name, [])))\n",
    ")\n",
    "\n",
    "# Step 2: Calculate experience (number of times elected)\n",
    "councillor_df[\"Experience at KCC (terms)\"] = councillor_df[election_dates].apply(\n",
    "    lambda row: sum(1 for value in row if value == \"Elected\"), axis=1\n",
    ")\n",
    "\n",
    "# Step 3: Reorder columns\n",
    "ordered_cols = [\"Division\", \"Latest Party\"] + election_dates + [\"Experience at KCC (terms)\", \"Past Parties\"]\n",
    "councillor_df = councillor_df[ordered_cols]\n",
    "\n",
    "councillor_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0522fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataframe as a CSV in the data/elections directory\n",
    "output_path = \"../data/elections/kent_councillors_elected_2025.csv\"\n",
    "councillor_df.to_csv(output_path)\n",
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba56b5",
   "metadata": {},
   "source": [
    "### KCC 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run after code reset\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Set target election date\n",
    "target_date = \"2021-05-06\"\n",
    "\n",
    "# Extract elected candidates from that date\n",
    "elected_2021 = []\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\":\n",
    "        continue\n",
    "    if record[\"election_date\"] != target_date:\n",
    "        continue\n",
    "    division = record[\"division\"]\n",
    "    for cand in record[\"candidates\"]:\n",
    "        if cand[\"outcome\"] == \"Elected\":\n",
    "            elected_2021.append({\n",
    "                \"name\": cand[\"name\"].strip(),\n",
    "                \"division\": division,\n",
    "                \"first_name\": cand.get(\"first_name\", \"\").strip(),\n",
    "                \"last_name\": cand.get(\"last_name\", \"\").strip(),\n",
    "                \"middle_names\": cand.get(\"middle_names\", \"\").strip(),\n",
    "                \"party\": cand[\"party\"].strip()\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "elected_2021_df = pd.DataFrame(elected_2021)\n",
    "\n",
    "\n",
    "# Save the final dataframe as a CSV in the data/elections directory\n",
    "output_path = \"../data/elections/kent_councillors_elected_2021_short.csv\"\n",
    "elected_2021_df.to_csv(output_path)\n",
    "output_path\n",
    "\n",
    "elected_2021_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Target election date\n",
    "target_date = \"2025-05-01\"\n",
    "elected_2021 = []\n",
    "\n",
    "for record in data:\n",
    "    if record.get(\"status\") != \"ok\" or record.get(\"election_date\") != target_date:\n",
    "        continue\n",
    "    division = record.get(\"division\", \"\")\n",
    "    for cand in record[\"candidates\"]:\n",
    "        if cand.get(\"outcome\") == \"Elected\":\n",
    "            elected_2021.append({\n",
    "                \"name\": cand.get(\"name\", \"\").strip(),\n",
    "                \"division\": division,\n",
    "                \"first_name\": cand.get(\"first_name\", \"\").strip(),\n",
    "                \"last_name\": cand.get(\"last_name\", \"\").strip(),\n",
    "                \"middle_names\": cand.get(\"middle_names\", \"\").strip(),\n",
    "                \"party\": cand.get(\"party\", \"\").strip()\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "elected_2025_df = pd.DataFrame(elected_2021)\n",
    "\n",
    "# Save the final dataframe as a CSV in the data/elections directory\n",
    "output_path = \"../data/elections/kent_councillors_elected_2025_short.csv\"\n",
    "elected_2025_df.to_csv(output_path)\n",
    "output_path\n",
    "\n",
    "elected_2025_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dbe9b6",
   "metadata": {},
   "source": [
    "### Meetings mock up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af3ec7",
   "metadata": {},
   "source": [
    "## üß† What This Script Does: \"Who Is Who\" Councillor Classifier\n",
    "\n",
    "This script builds a \"Who Is Who\" registry by linking **meeting attendance records** (from council minutes) to **elected councillor data** across two electoral terms (2021 and 2025). It classifies each name mentioned in meeting minutes into one of three categories:\n",
    "\n",
    "### üîç Key Steps:\n",
    "\n",
    "1. **Load and Standardize Councillor Data**\n",
    "   - Reads two CSVs of elected councillors from 2021 and 2025.\n",
    "   - Standardizes names (e.g., lowercasing, ASCII stripping) to enable fuzzy matching.\n",
    "\n",
    "2. **Extract Attendee Names from JSONL Minutes**\n",
    "   - Opens a `.jsonl` file of meeting metadata.\n",
    "   - Pulls out unique names listed under 'present', 'absent', or 'virtual'.\n",
    "\n",
    "3. **Standardize Attendee Names**\n",
    "   - Removes titles like `Mr`, `Cllr`, `Dr`, etc.\n",
    "   - Splits names into initials and last names for pattern matching.\n",
    "\n",
    "4. **Flexible Matching Logic**\n",
    "   - Matches attendees to current or former councillors using:\n",
    "     - Exact last name\n",
    "     - Fuzzy regex on first initials\n",
    "   - Categorizes results into:\n",
    "     - `current` councillor\n",
    "     - `former` councillor\n",
    "     - `civil_servant` (if no match found)\n",
    "     - `needs_review` (if ambiguous matches found)\n",
    "\n",
    "5. **Export Final Dataset**\n",
    "   - Outputs a clean CSV (`who_is_who.csv`) with:\n",
    "     - Raw name\n",
    "     - Match info (first, last, division, party)\n",
    "     - Status tag (`current`, `former`, `civil_servant`, `needs_review`)\n",
    "\n",
    "### ‚úÖ Result:\n",
    "This enables downstream systems to recognize **who's who** in meeting minutes, distinguishing between elected representatives and council staff or visitors ‚Äî essential for analytics, attendance stats, or knowledge graphs.\n",
    "\n",
    "This is just an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66357b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "MINUTES_PATH = Path(\"/Users/lgfolder/github/council-assistant/data/document_metadata/metadata_test.jsonl\")\n",
    "#MINUTES_PATH = Path(\"/Users/lgfolder/github/council-assistant/data/metadata/meetings.jsonl\")\n",
    "COUNCILLORS_2025_CSV = Path(\"/Users/lgfolder/github/council-assistant/data/elections/kent_councillors_elected_2025_short.csv\")\n",
    "COUNCILLORS_2021_CSV = Path(\"/Users/lgfolder/github/council-assistant/data/elections/kent_councillors_elected_2021_short.csv\")\n",
    "OUTPUT_PATH = Path(\"/Users/lgfolder/github/council-assistant/data/who_is_who.csv\")\n",
    "\n",
    "def load_and_standardize_councillors(current_csv: Path, previous_csv: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Load both current and previous councillor data with standardized names\"\"\"\n",
    "    def process_councillors(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Handle different column name variations\n",
    "        first_name_col = next((col for col in df.columns if 'first' in col.lower()), None)\n",
    "        last_name_col = next((col for col in df.columns if 'last' in col.lower()), None)\n",
    "        \n",
    "        if not first_name_col or not last_name_col:\n",
    "            raise ValueError(\"Could not find first_name and last_name columns in councillor data\")\n",
    "        \n",
    "        df['standard_first'] = (\n",
    "            df[first_name_col]\n",
    "            .astype(str)\n",
    "            .str.lower()\n",
    "            .str.strip()\n",
    "            .str.normalize('NFKD')\n",
    "            .str.encode('ascii', errors='ignore')\n",
    "            .str.decode('utf-8')\n",
    "        )\n",
    "        df['standard_last'] = (\n",
    "            df[last_name_col]\n",
    "            .astype(str)\n",
    "            .str.lower()\n",
    "            .str.strip()\n",
    "            .str.normalize('NFKD')\n",
    "            .str.encode('ascii', errors='ignore')\n",
    "            .str.decode('utf-8')\n",
    "        )\n",
    "        \n",
    "        # Handle division/ward/department naming\n",
    "        division_col = next((col for col in df.columns if any(x in col.lower() for x in ['division', 'ward', 'district'])), None)\n",
    "        if division_col:\n",
    "            df['division'] = df[division_col]\n",
    "        else:\n",
    "            df['division'] = ''\n",
    "            \n",
    "        # Handle party/group naming\n",
    "        party_col = next((col for col in df.columns if any(x in col.lower() for x in ['party', 'group'])), None)\n",
    "        if party_col:\n",
    "            df['party'] = df[party_col]\n",
    "        else:\n",
    "            df['party'] = ''\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    try:\n",
    "        current = process_councillors(pd.read_csv(current_csv))\n",
    "        previous = process_councillors(pd.read_csv(previous_csv))\n",
    "        return current, previous\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading councillor data: {e}\")\n",
    "        raise\n",
    "\n",
    "def parse_minute_names(minutes_path: Path) -> List[str]:\n",
    "    \"\"\"Extract all unique names from meeting minutes\"\"\"\n",
    "    attendees = set()\n",
    "    \n",
    "    with open(minutes_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                meeting = json.loads(line)\n",
    "                for status in ['present', 'absent', 'virtual']:\n",
    "                    for name in meeting['attendance'].get(status, []):\n",
    "                        attendees.add(name.strip())\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    return list(attendees)\n",
    "\n",
    "def standardize_minutes_name(name: str) -> Tuple[str, str]:\n",
    "    \"\"\"Convert council minutes names to standardized format\"\"\"\n",
    "    # Remove honorifics and trailing periods\n",
    "    clean_name = re.sub(\n",
    "        r'^(Mr|Mrs|Ms|Miss|Sir|Dr|Cllr)\\.?\\s+', \n",
    "        '', \n",
    "        name, \n",
    "        flags=re.IGNORECASE\n",
    "    ).strip()\n",
    "    \n",
    "    # Handle cases with multiple initials\n",
    "    parts = [p.strip('. ') for p in clean_name.split() if p.strip()]\n",
    "    \n",
    "    if not parts:\n",
    "        return ('', '')\n",
    "    \n",
    "    last_name = parts[-1]\n",
    "    first_parts = parts[:-1]\n",
    "    \n",
    "    if not first_parts:\n",
    "        return ('', last_name.lower())\n",
    "    \n",
    "    # Create first initial pattern (e.g., \"R W\" becomes \"r.?w.?\")\n",
    "    first_initials = ''.join([f\"{p[0].lower()}.*\" for p in first_parts if p])\n",
    "    \n",
    "    return (first_initials, last_name.lower())\n",
    "\n",
    "def find_councillor_match(first: str, last: str, councillors: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Find matching councillors using flexible matching\"\"\"\n",
    "    # Exact last name match\n",
    "    matches = councillors[councillors['standard_last'] == last]\n",
    "    \n",
    "    if not first:\n",
    "        return matches\n",
    "    \n",
    "    # Flexible first initial matching (e.g., \"r.?w.?\" matches \"Roger William\")\n",
    "    try:\n",
    "        pattern = re.compile(f'^{first}')\n",
    "        return matches[\n",
    "            matches['standard_first'].str.contains(pattern, na=False)\n",
    "        ]\n",
    "    except:\n",
    "        return matches\n",
    "\n",
    "def classify_attendees(\n",
    "    attendees: List[str], \n",
    "    current_councillors: pd.DataFrame,\n",
    "    previous_councillors: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Classify each attendee into categories\"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for raw_name in attendees:\n",
    "        first, last = standardize_minutes_name(raw_name)\n",
    "        \n",
    "        # Check current councillors first\n",
    "        current_matches = find_councillor_match(first, last, current_councillors)\n",
    "        previous_matches = find_councillor_match(first, last, previous_councillors)\n",
    "        \n",
    "        if len(current_matches) == 1:\n",
    "            # Current councillor match\n",
    "            record = create_record(raw_name, current_matches.iloc[0], 'current')\n",
    "        elif len(previous_matches) == 1:\n",
    "            # Former councillor match\n",
    "            record = create_record(raw_name, previous_matches.iloc[0], 'former')\n",
    "        elif len(current_matches) > 1 or len(previous_matches) > 1:\n",
    "            # Ambiguous match\n",
    "            record = create_ambiguous_record(raw_name, first, last, current_matches, previous_matches)\n",
    "        else:\n",
    "            # No match - likely civil servant\n",
    "            record = create_civil_servant_record(raw_name, first, last)\n",
    "        \n",
    "        records.append(record)\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def create_record(raw_name: str, councillor: pd.Series, status: str) -> Dict:\n",
    "    \"\"\"Create standardized record for matched councillor\"\"\"\n",
    "    return {\n",
    "        'raw_name': raw_name,\n",
    "        'first_name': councillor.get('first_name', ''),\n",
    "        'last_name': councillor.get('last_name', ''),\n",
    "        'position': 'Councillor',\n",
    "        'division': councillor.get('division', ''),\n",
    "        'party': councillor.get('party', ''),\n",
    "        'status': status,\n",
    "        'source': 'current' if status == 'current' else 'previous'\n",
    "    }\n",
    "\n",
    "def create_ambiguous_record(\n",
    "    raw_name: str, \n",
    "    first: str, \n",
    "    last: str,\n",
    "    current_matches: pd.DataFrame,\n",
    "    previous_matches: pd.DataFrame\n",
    ") -> Dict:\n",
    "    \"\"\"Create record for ambiguous matches\"\"\"\n",
    "    all_matches = pd.concat([current_matches, previous_matches])\n",
    "    return {\n",
    "        'raw_name': raw_name,\n",
    "        'first_name': '',\n",
    "        'last_name': last.title(),\n",
    "        'position': 'AMBIGUOUS',\n",
    "        'division': '|'.join(all_matches.get('division', '').unique()),\n",
    "        'party': '|'.join(all_matches.get('party', '').unique()),\n",
    "        'status': 'needs_review',\n",
    "        'source': 'multiple'\n",
    "    }\n",
    "\n",
    "def create_civil_servant_record(raw_name: str, first: str, last: str) -> Dict:\n",
    "    \"\"\"Create record for civil servants\"\"\"\n",
    "    formatted_first = ' '.join([f\"{c.upper()}.\" for c in first.split('.') if c]) if first else ''\n",
    "    return {\n",
    "        'raw_name': raw_name,\n",
    "        'first_name': formatted_first,\n",
    "        'last_name': last.title(),\n",
    "        'position': 'Civil Servant',\n",
    "        'division': '',\n",
    "        'party': '',\n",
    "        'status': 'civil_servant',\n",
    "        'source': ''\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load and standardize councillor data\n",
    "        current_councillors, previous_councillors = load_and_standardize_councillors(\n",
    "            COUNCILLORS_2025_CSV, \n",
    "            COUNCILLORS_2021_CSV\n",
    "        )\n",
    "        \n",
    "        # Parse meeting attendees\n",
    "        attendees = parse_minute_names(MINUTES_PATH)\n",
    "        \n",
    "        # Classify attendees\n",
    "        who_is_who = classify_attendees(attendees, current_councillors, previous_councillors)\n",
    "        \n",
    "        # Save results\n",
    "        who_is_who.to_csv(OUTPUT_PATH, index=False)\n",
    "        print(f\"Processed {len(who_is_who)} names. Saved to {OUTPUT_PATH}\")\n",
    "        print(\"\\nSample output:\")\n",
    "        print(who_is_who.head().to_string())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the processed data\n",
    "who_is_who = pd.read_csv(\"../data/who_is_who.csv\")\n",
    "\n",
    "# 1. Current Councillors Table\n",
    "current_councillors = who_is_who[who_is_who['status'] == 'current'].copy()\n",
    "current_councillors['full_name'] = current_councillors['first_name'] + ' ' + current_councillors['last_name']\n",
    "councillors_table = current_councillors[['full_name', 'division', 'party', 'last_name']].sort_values('last_name')\n",
    "councillors_table = councillors_table[['full_name', 'division', 'party']]  # Drop last_name after sorting\n",
    "\n",
    "# 2. Civil Servants Directory\n",
    "civil_servants = who_is_who[who_is_who['status'] == 'civil_servant'].copy()\n",
    "civil_servants['formatted_name'] = civil_servants['first_name'] + ' ' + civil_servants['last_name']\n",
    "civil_servants_table = civil_servants[['formatted_name', 'raw_name', 'last_name']].sort_values('last_name')\n",
    "civil_servants_table = civil_servants_table[['formatted_name', 'raw_name']]  # Drop last_name after sorting\n",
    "\n",
    "# 3. Meeting Participation Heatmap\n",
    "# First we need to count meeting appearances (this would be better done during initial processing)\n",
    "def count_meetings(minutes_path):\n",
    "    meeting_counts = {}\n",
    "    with open(minutes_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                meeting = json.loads(line)\n",
    "                for status in ['present', 'absent', 'virtual']:\n",
    "                    for name in meeting['attendance'].get(status, []):\n",
    "                        meeting_counts[name.strip()] = meeting_counts.get(name.strip(), 0) + 1\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return meeting_counts\n",
    "\n",
    "meeting_counts = count_meetings(MINUTES_PATH)\n",
    "who_is_who['meetings_attended'] = who_is_who['raw_name'].map(meeting_counts).fillna(0)\n",
    "\n",
    "participation_table = who_is_who[\n",
    "    ['first_name', 'last_name', 'position', 'meetings_attended']\n",
    "].sort_values('meetings_attended', ascending=False)\n",
    "\n",
    "# 4. Department Affiliations\n",
    "department_table = who_is_who.groupby(['division', 'position']).size().unstack(fill_value=0)\n",
    "department_table['Total'] = department_table.sum(axis=1)\n",
    "\n",
    "# 5. Ambiguity Resolution Table\n",
    "ambiguity_table = who_is_who[who_is_who['status'] == 'needs_review'].copy()\n",
    "ambiguity_table['possible_matches'] = ambiguity_table.apply(\n",
    "    lambda x: f\"{x['division']} ({x['party']})\", axis=1\n",
    ")\n",
    "ambiguity_table = ambiguity_table[['raw_name', 'possible_matches']]\n",
    "\n",
    "# Save all tables\n",
    "tables_path = Path(\"/Users/lgfolder/github/council-assistant/data/who_is_who_tables/\")\n",
    "tables_path.mkdir(exist_ok=True)\n",
    "\n",
    "councillors_table.to_csv(tables_path / \"councillors.csv\", index=False)\n",
    "civil_servants_table.to_csv(tables_path / \"civil_servants.csv\", index=False)\n",
    "participation_table.to_csv(tables_path / \"participation.csv\", index=False)\n",
    "department_table.to_csv(tables_path / \"divisions.csv\")\n",
    "ambiguity_table.to_csv(tables_path / \"ambiguities.csv\", index=False)\n",
    "\n",
    "print(\"All tables generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0987a",
   "metadata": {},
   "source": [
    "### Generate elections json from the elections results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c713f65",
   "metadata": {},
   "source": [
    "## üó≥Ô∏è What This Script Does: `elections.jsonl` Metadata Generator\n",
    "\n",
    "This script creates a machine-readable reference file (`elections.jsonl`) that describes each **election year** found in your cleaned Kent County Council results dataset.\n",
    "\n",
    "### üì¶ Input\n",
    "- Loads the cleaned election results from:  \n",
    "  `../data/elections/kent_results_all_years_cleaned.json`  \n",
    "  This file contains detailed candidate-level results for all elections and by-elections.\n",
    "\n",
    "### ‚öôÔ∏è What It Builds\n",
    "It generates one metadata entry per **election year**, each including:\n",
    "\n",
    "| Field | Description |\n",
    "|-------|-------------|\n",
    "| `election_id` | Unique ID like `kent_cc_2025` |\n",
    "| `council_id` | Fixed as `\"kent_cc\"` |\n",
    "| `election_date` | ISO date of the election (from first result that year) |\n",
    "| `election_type` | `\"local\"` |\n",
    "| `scope` | `\"county-wide\"` (assumes all are full council elections) |\n",
    "| `description` | Human-readable description like `\"Kent County Council local elections 2025\"` |\n",
    "| `results_path` | File path to the full dataset |\n",
    "| `results_filter` | A filter dictionary, e.g. `{\"election_year\": 2025}` to slice the dataset |\n",
    "| `source_url` | Link to the council's official elections page |\n",
    "\n",
    "### üßæ Output\n",
    "- Writes the data to a `.jsonl` file at:  \n",
    "  `../data/references/elections.jsonl`  \n",
    "  This can be used for indexing, display in UI menus, filtering APIs, or building dashboards.\n",
    "\n",
    "### ‚úÖ Example Use Cases\n",
    "- Generating dropdowns like **\"View Results for 2025\"**\n",
    "- Linking knowledge graph events to specific election cycles\n",
    "- Running time-series analyses across elections\n",
    "\n",
    "This metadata file acts as a lightweight index of all the **election cycles** your project has data for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned results\n",
    "input_path = Path(\"../data/elections/kent_results_all_years_cleaned.jsonl\")\n",
    "results_data = pd.read_json(input_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Basic shape\n",
    "print(f\"üì¶ Shape: {results_data.shape[0]:,} rows √ó {results_data.shape[1]} columns\")\n",
    "\n",
    "# Basic info\n",
    "print(\"\\nüîç Data Types & Non-Null Counts:\")\n",
    "print(results_data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nüö´ Missing Values per Column:\")\n",
    "missing_counts = results_data.isna().sum()\n",
    "print(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Value counts of election types\n",
    "if \"election_type\" in results_data.columns:\n",
    "    print(\"\\nüó≥Ô∏è Election Type Breakdown:\")\n",
    "    print(results_data[\"election_type\"].value_counts(dropna=False))\n",
    "\n",
    "# Year coverage\n",
    "if \"election_date\" in results_data.columns:\n",
    "    results_data[\"election_date\"] = pd.to_datetime(results_data[\"election_date\"], errors=\"coerce\")\n",
    "    results_data[\"election_year\"] = results_data[\"election_date\"].dt.year\n",
    "    print(\"\\nüìÜ Election Years Available:\")\n",
    "    print(results_data[\"election_year\"].value_counts().sort_index())\n",
    "\n",
    "# Division name checks\n",
    "if \"division\" in results_data.columns:\n",
    "    print(\"\\nüè∑Ô∏è Top 10 Most Frequent Division Names:\")\n",
    "    print(results_data[\"division\"].value_counts().head(10))\n",
    "\n",
    "# Status field analysis\n",
    "if \"status\" in results_data.columns:\n",
    "    print(\"\\n‚úÖ Status Value Counts:\")\n",
    "    print(results_data[\"status\"].value_counts())\n",
    "\n",
    "# Candidate-level checks\n",
    "candidate_counts = results_data[\"candidates\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "print(f\"\\nüë• Candidate counts per record:\\n- Mean: {candidate_counts.mean():.2f}, Max: {candidate_counts.max()}, Min: {candidate_counts.min()}\")\n",
    "print(f\"- Records with 0 candidates: {(candidate_counts == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c945e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with missing election_date\n",
    "missing_election_date = results_data[results_data[\"election_date\"].isna()]\n",
    "\n",
    "print(f\"‚ö†Ô∏è Found {missing_election_date.shape[0]} rows without an election date.\")\n",
    "\n",
    "# Display them\n",
    "missing_election_date.head(20)  # You can change 20 to see more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ed8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_path = Path(\"../data/references/elections.jsonl\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add election year column from date\n",
    "results_data[\"election_year\"] = pd.to_datetime(results_data[\"election_date\"]).dt.year\n",
    "\n",
    "# Define base fields\n",
    "council_id = \"kent_cc\"\n",
    "source_url = \"https://www.kent.gov.uk/about-the-council/how-the-council-works/elections\"\n",
    "results_path = str(input_path)\n",
    "\n",
    "# Generate one entry per unique election year\n",
    "elections = []\n",
    "\n",
    "for year in sorted(results_data[\"election_year\"].unique(), reverse=True):\n",
    "    # Filter records for this year that have a valid election_date\n",
    "    subset = results_data[\n",
    "        (results_data[\"election_year\"] == year) & \n",
    "        (results_data[\"election_date\"].notnull())\n",
    "    ]\n",
    "\n",
    "    if subset.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping year {year} ‚Äî no valid election_date found.\")\n",
    "        continue\n",
    "\n",
    "    # Use the first valid election_date\n",
    "    election_date = pd.to_datetime(subset[\"election_date\"].iloc[0]).date().isoformat()\n",
    "\n",
    "    election = {\n",
    "        \"election_id\": f\"{council_id}_{int(year)}\",\n",
    "        \"council_id\": council_id,\n",
    "        \"election_date\": election_date,\n",
    "        \"election_type\": \"local\",\n",
    "        \"scope\": \"county-wide\",\n",
    "        \"description\": f\"Kent County Council local elections {year}\",\n",
    "        \"results_path\": str(input_path),\n",
    "        \"results_filter\": {\"election_year\": int(year)},\n",
    "        \"source_url\": source_url\n",
    "    }\n",
    "\n",
    "    elections.append(election)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3040b40",
   "metadata": {},
   "source": [
    "### Populate people.json from existing civil servants json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d41c94c",
   "metadata": {},
   "source": [
    "The civil servant json was already available - generated by ChatGPT from a pdf I found on the council's website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "INPUT_FILE = Path(\"../data/jsons/civil_servants_all.json\")\n",
    "OUTPUT_FILE = Path(\"../data/entities/people.jsonl\")\n",
    "OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === UTILITY FUNCTIONS ===\n",
    "def slugify(name):\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", name.lower()).strip(\"_\")\n",
    "\n",
    "def generate_person_id(slug, counter):\n",
    "    return f\"{slug}_{counter:03d}\"\n",
    "\n",
    "# === LOAD EXISTING PEOPLE ===\n",
    "existing_people = {}\n",
    "slug_counter = {}\n",
    "\n",
    "if OUTPUT_FILE.exists():\n",
    "    with open(OUTPUT_FILE) as f:\n",
    "        for line in f:\n",
    "            person = json.loads(line)\n",
    "            slug = slugify(person[\"full_name\"])\n",
    "            existing_people[slug] = person\n",
    "            # update counter\n",
    "            id_suffix = person[\"person_id\"].split(\"_\")[-1]\n",
    "            try:\n",
    "                slug_counter[slug] = max(slug_counter.get(slug, 0), int(id_suffix))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "# === LOAD CIVIL SERVANTS DATA ===\n",
    "with open(INPUT_FILE) as f:\n",
    "    civil_servants = json.load(f)\n",
    "\n",
    "new_people = []\n",
    "flagged_people = []\n",
    "\n",
    "for entry in civil_servants:\n",
    "    full_name = entry.get(\"name\", \"\").strip()\n",
    "    if not full_name:\n",
    "        continue\n",
    "\n",
    "    parts = full_name.split()\n",
    "    first_name = parts[0] if parts else \"\"\n",
    "    last_name = parts[-1] if len(parts) > 1 else \"\"\n",
    "    slug = slugify(full_name)\n",
    "\n",
    "    if slug in existing_people:\n",
    "        flagged_people.append(full_name)\n",
    "        continue  # Skip known person\n",
    "\n",
    "    # Assign new person_id\n",
    "    slug_counter[slug] = slug_counter.get(slug, 0) + 1\n",
    "    person_id = generate_person_id(slug, slug_counter[slug])\n",
    "\n",
    "    person = {\n",
    "        \"person_id\": person_id,\n",
    "        \"full_name\": full_name,\n",
    "        \"first_name\": first_name,\n",
    "        \"last_name\": last_name,\n",
    "        \"aliases\": list({full_name, last_name}),\n",
    "        \"roles\": [\"civil_servant\"],\n",
    "        \"civil_service_roles\": [{\n",
    "            \"role\": entry.get(\"role\", \"\"),\n",
    "            \"department\": entry.get(\"department\", \"\"),\n",
    "            \"division\": entry.get(\"Division\", \"\"),\n",
    "            \"service_unit\": entry.get(\"Service Unit\", \"\"),\n",
    "            \"grade\": entry.get(\"Grade\", \"\"),\n",
    "            \"contract_title\": entry.get(\"Contract Title\", \"\"),\n",
    "            \"manager_name\": entry.get(\"Manager Name\", \"\"),\n",
    "            \"start_date\": \"\",\n",
    "            \"end_date\": \"\"\n",
    "        }],\n",
    "        \"committees\": entry.get(\"committees\", []),\n",
    "        \"elections\": [],\n",
    "        \"profiles\": {\n",
    "            \"council_url\": \"\",\n",
    "            \"linkedin\": \"\",\n",
    "            \"twitter\": \"\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    new_people.append(person)\n",
    "    existing_people[slug] = person\n",
    "\n",
    "# === APPEND TO people.jsonl ===\n",
    "mode = \"a\" if OUTPUT_FILE.exists() else \"w\"\n",
    "with open(OUTPUT_FILE, mode) as f:\n",
    "    for person in new_people:\n",
    "        f.write(json.dumps(person) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Added {len(new_people)} new civil servants to: {OUTPUT_FILE}\")\n",
    "if flagged_people:\n",
    "    print(f\"‚ö†Ô∏è  Skipped {len(flagged_people)} possible duplicates:\")\n",
    "    for name in flagged_people:\n",
    "        print(\" -\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f05f50",
   "metadata": {},
   "source": [
    "### Append Candidates to people.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24713713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "ELECTION_FILE = Path(\"../data/elections/kent_results_all_years_cleaned.jsonl\")\n",
    "PEOPLE_FILE = Path(\"../data/metadata/people.jsonl\")\n",
    "PEOPLE_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === UTILITY FUNCTIONS ===\n",
    "def slugify(name):\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", name.lower()).strip(\"_\")\n",
    "\n",
    "def generate_person_id(base_slug, counter):\n",
    "    return f\"{base_slug}_{counter:03d}\"\n",
    "\n",
    "# === LOAD EXISTING PEOPLE ===\n",
    "existing_people = {}\n",
    "slug_counter = {}\n",
    "\n",
    "if PEOPLE_FILE.exists():\n",
    "    with open(PEOPLE_FILE) as f:\n",
    "        for line in f:\n",
    "            person = json.loads(line)\n",
    "            slug = slugify(person[\"full_name\"])\n",
    "            existing_people[slug] = person\n",
    "            slug_counter[slug] = int(person[\"person_id\"].split(\"_\")[-1])\n",
    "\n",
    "# === LOAD ELECTION RESULTS ===\n",
    "with open(ELECTION_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    election_data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# === PROCESS NEW CANDIDATES ===\n",
    "for record in election_data:\n",
    "    year = int(record.get(\"election_date\", \"\")[:4])\n",
    "    division = record.get(\"division\", \"\")\n",
    "    \n",
    "    for cand in record.get(\"candidates\", []):\n",
    "        canonical_name = cand.get(\"canonical_name\", cand.get(\"name\", \"\")).strip()\n",
    "        if not canonical_name:\n",
    "            continue\n",
    "\n",
    "        slug = slugify(canonical_name)\n",
    "        first, *rest = canonical_name.split()\n",
    "        last = rest[-1] if rest else first\n",
    "\n",
    "        # Prepare the election record\n",
    "        election_info = {\n",
    "            \"year\": year,\n",
    "            \"division\": division,\n",
    "            \"party\": cand.get(\"party\", \"\"),\n",
    "            \"status\": cand.get(\"status\", \"\")\n",
    "        }\n",
    "\n",
    "        if slug in existing_people:\n",
    "            # Append election to existing person if not a duplicate\n",
    "            existing = existing_people[slug]\n",
    "            if election_info not in existing[\"elections\"]:\n",
    "                existing[\"elections\"].append(election_info)\n",
    "        else:\n",
    "            # New person: assign new ID\n",
    "            slug_counter[slug] = slug_counter.get(slug, 0) + 1\n",
    "            person_id = generate_person_id(slug, slug_counter[slug])\n",
    "\n",
    "            new_person = {\n",
    "                \"person_id\": person_id,\n",
    "                \"full_name\": canonical_name,\n",
    "                \"first_name\": first,\n",
    "                \"last_name\": last,\n",
    "                \"aliases\": list({canonical_name, last}),\n",
    "                \"roles\": [\"candidate\"],\n",
    "                \"civil_service_roles\": [],\n",
    "                \"committees\": [],\n",
    "                \"elections\": [election_info],\n",
    "                \"profiles\": {\n",
    "                    \"council_url\": \"\",\n",
    "                    \"linkedin\": \"\",\n",
    "                    \"twitter\": \"\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "            existing_people[slug] = new_person\n",
    "\n",
    "# === WRITE UPDATED PEOPLE FILE ===\n",
    "with open(PEOPLE_FILE, \"w\") as f:\n",
    "    for person in existing_people.values():\n",
    "        f.write(json.dumps(person) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ people.jsonl updated with {len(existing_people)} unique individuals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3587f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# ðŸ“˜ Council Assistant â€“ Project Overview

The **Council Assistant** is a local-government-focused document intelligence platform designed to assist teams in searching, summarising, and interacting with meeting documents such as agendas, minutes, appendices, reports, and motions. It uses a metadata-indexed RAG pipeline, built on OpenAI embeddings, and is structured around a meeting-centric file organisation.

---

## ðŸ“‚ Current Project Structure (as of May 2025)

```
council-assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ embeddings/                  # Future home for production app logic (chatbot)
â”‚   â””â”€â”€ utils/                       # Reserved for helper functions (currently empty)
â”‚
â”œâ”€â”€ archive/                         # Archived legacy scripts or versions no longer in use
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ council_documents/                    # Meeting-centric raw documents (PDFs)
â”‚   â”‚   â”œâ”€â”€ cabinet/                          # Top-level committee folder
â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-01-30/                   # Meeting date
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ originals/                # Original scraped PDFs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunks/                   # Chunked JSON files (optional, future)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ metadata.json             # Metadata describing documents in this meeting
â”‚   â”‚   â”œâ”€â”€ full_council/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2025-03-13/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ originals/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunks/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â”‚   â””â”€â”€ duplicates/                       # Duplicate PDFs safely moved here during de-duplication
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/                 # FAISS indexes + embedding metadata
â”‚   â”‚   â”œâ”€â”€ council_index.faiss
â”‚   â”‚   â”œâ”€â”€ council_index_large.faiss
â”‚   â”‚   â”œâ”€â”€ metadata.jsonl
â”‚   â”‚   â””â”€â”€ metadata_large.jsonl
â”‚   â”‚
â”‚   â”œâ”€â”€ processed_register/        # Canonical metadata tracking
â”‚   â”‚   â”œâ”€â”€ document_ids.json      # Mapping: relative file path â†’ doc_id + content hash
â”‚   â”‚   â””â”€â”€ document_manifest.jsonl # Status tracking: chunked / embedded / duplicated / removed
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_Scraping_council_docs_KCC.ipynb      # Main scraping notebook
â”‚   â””â”€â”€ 2_Duplicate_hashes.ipynb               # Notebook for auditing and reviewing duplicates
â”‚
â”œâ”€â”€ scripts/                        # Finalised script pipeline (chronologically ordered)
â”‚   â”œâ”€â”€ 1_scraping_council_docs_DRAFT.py       # Main scraper + initial metadata writer
â”‚   â”œâ”€â”€ 2_assign_document_ids.py               # Assigns doc_ids + hashes + deduplicates
â”‚   â”œâ”€â”€ 3_chunking_master.py                   # Context-aware chunking pipeline
â”‚   â””â”€â”€ 4_embedding_master.py                  # Embedding with OpenAI, both small & large models
â”‚
â”œâ”€â”€ README.md                      # This file
```

---

## âœ… Functional Pipeline Summary

### **1. Scraping & Initial Metadata** (`1_scraping_council_docs_DRAFT.py` or notebook)

* Extracts PDF documents from public council pages
* Allocates them into the correct committee/date/originals folder
* Writes basic `metadata.json` per meeting

### **2. Document ID Assignment & Deduplication** (`2_assign_document_ids.py`)

* Assigns unique `doc_id` to each file based on content hash
* Detects and removes true duplicates (with rules on suffix `_1`, URL presence, etc.)
* Updates `document_ids.json` and `document_manifest.jsonl`

### **3. Chunking** (`3_chunking_master.py`)

* Processes PDFs into semantic chunks (overlapping if needed)
* Stores `.json` chunk files locally
* Updates manifest with status + chunk path

### **4. Embeddings** (`4_embedding_master.py`)

* Embeds chunked files using OpenAI models
* Supports both `text-embedding-3-small` and `text-embedding-3-large`
* Writes metadata and builds FAISS index
* Tracks progress in `document_manifest.jsonl`

---

## ðŸ§  RAG-Ready Metadata Design

* Each document has a `doc_id`, relative path, and hash
* Each chunk has its `chunk_id`, `doc_id`, text, and source
* Manifest file includes status flags:

  * `ready_for_chunking`
  * `chunked`
  * `ready_for_embedding`
  * `embedded`
  * `embedding_large` (optional field)
  * `duplicate_removed` (optional)

---

## ðŸš§ Next Steps

* [ ] Build notebook-based chatbot using FAISS + OpenAI completion
* [ ] Test retrieval quality using both embedding models
* [ ] Add user history, session memory, or user-level auth (future app layer)

